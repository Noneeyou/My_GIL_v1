import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GCNConv


# ========= 1ï¸âƒ£ å›¾ç¼–ç å™¨éƒ¨åˆ† =========
class GCNEncoder(nn.Module):
    """
    åŸºç¡€å›¾å·ç§¯ç¼–ç å™¨ï¼Œç”¨äºæå–ç»“æ„åŒ–ç‰¹å¾ã€‚
    """
    def __init__(self, in_dim, hidden_dim, out_dim):
        super(GCNEncoder, self).__init__()
        self.conv1 = GCNConv(in_dim, hidden_dim)
        self.conv2 = GCNConv(hidden_dim, out_dim)

    def forward(self, x, edge_index):
        x = F.relu(self.conv1(x, edge_index))
        x = self.conv2(x, edge_index)
        return x


# ========= 2ï¸âƒ£ æŠ•å½±å¤´éƒ¨åˆ† =========
class MLPHead(nn.Module):
    """
    æŠ•å½±å¤´ï¼Œå°†ç¼–ç å™¨è¾“å‡ºæ˜ å°„åˆ°å¯¹æ¯”ç©ºé—´ã€‚
    """
    def __init__(self, in_dim, proj_dim):
        super(MLPHead, self).__init__()
        self.fc1 = nn.Linear(in_dim, proj_dim)
        self.fc2 = nn.Linear(proj_dim, proj_dim)

    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x


# ========= 3ï¸âƒ£ å°è£…ç±»ï¼šGraphContrastiveLearner =========
class GraphContrastiveLearner(nn.Module):
    """
    å›¾å¯¹æ¯”å­¦ä¹ æ¨¡å—ï¼š
    - å†…å«ç¼–ç å™¨ + æŠ•å½±å¤´
    - æä¾›ç‰¹å¾æå–ä¸å¯¹æ¯”æŸå¤±è®¡ç®—
    """
    def __init__(self, in_dim, hidden_dim, out_dim, proj_dim, tau=0.5):
        super(GraphContrastiveLearner, self).__init__()
        self.encoder = GCNEncoder(in_dim, hidden_dim, out_dim)
        self.projector = MLPHead(out_dim, proj_dim)
        self.tau = tau

    def forward(self, x, edge_index):
        """
        å‰å‘è®¡ç®—ï¼Œè¿”å›ç¼–ç å™¨ç‰¹å¾ h å’ŒæŠ•å½±ç‰¹å¾ z
        """
        h = self.encoder(x, edge_index)
        z = self.projector(h)
        return h, z

    def info_nce_loss(self, z1, z2):
        """
        è®¡ç®— InfoNCE å¯¹æ¯”å­¦ä¹ æŸå¤±
        """
        z1 = F.normalize(z1, dim=1)
        z2 = F.normalize(z2, dim=1)

        sim_matrix = torch.matmul(z1, z2.T) / self.tau
        sim_matrix = torch.exp(sim_matrix)

        pos = sim_matrix.diag()
        loss = -torch.log(pos / (sim_matrix.sum(dim=1) + 1e-8))
        return loss.mean()

    def compute_loss(self, x1, edge_index1, x2, edge_index2):
        """
        ä¸€æ­¥å¼è®¡ç®—ï¼ˆç¼–ç  + æŠ•å½± + æŸå¤±ï¼‰
        """
        _, z1 = self.forward(x1, edge_index1)
        _, z2 = self.forward(x2, edge_index2)
        loss = self.info_nce_loss(z1, z2)
        return loss

    
def summarize_graph(data):
    # ======== æ‰“å°å›¾çš„åŸºæœ¬ä¿¡æ¯ ========
    print("\n" + "="*60)
    print("ğŸ§© Graph Data Summary")
    print("="*60)

    # èŠ‚ç‚¹ä¿¡æ¯
    num_nodes = data.num_nodes if hasattr(data, 'num_nodes') else data.x.size(0)
    num_features = data.num_features if hasattr(data, 'num_features') else data.x.size(1)
    print(f"ğŸ“Š èŠ‚ç‚¹æ•°é‡ (num_nodes): {num_nodes}")
    print(f"ğŸ“ˆ èŠ‚ç‚¹ç‰¹å¾ç»´åº¦ (num_features): {num_features}")

    # è¾¹ä¿¡æ¯
    if hasattr(data, "edge_index"):
        num_edges = data.edge_index.size(1)
        print(f"ğŸ”— è¾¹æ•°é‡ (num_edges): {num_edges}")

        # æ£€æŸ¥æ˜¯å¦æœ‰è‡ªç¯æˆ–é‡å¤è¾¹
        src, dst = data.edge_index
        self_loops = (src == dst).sum().item()
        print(f"ğŸ” è‡ªç¯æ•°é‡ (self-loops): {self_loops}")

    # å…¶ä»–ä¿¡æ¯
    if hasattr(data, "edge_attr") and data.edge_attr is not None:
        print(f"âš™ï¸ è¾¹ç‰¹å¾ç»´åº¦ (edge_attr_dim): {data.edge_attr.size(1)}")

    if hasattr(data, "y") and data.y is not None:
        print(f"ğŸ¯ æ ‡ç­¾ç»´åº¦ (y_dim): {data.y.shape}")

    # æ‰“å°å­˜å‚¨é”®å€¼
    print(f"\nğŸ§¾ Dataå¯¹è±¡åŒ…å«å­—æ®µ: {list(data.keys())}")
    print("="*60 + "\n")

def augment_graph(data, feature_drop_prob=0.1, edge_drop_prob=0.1, noise_std=0.01):
    """
    å¯¹è¾“å…¥çš„ PyG Data å¯¹è±¡è¿›è¡Œå¢å¼º
    --------------------------------
    feature_drop_prob : float
        éšæœºmaskèŠ‚ç‚¹ç‰¹å¾çš„æ¯”ä¾‹
    edge_drop_prob : float
        éšæœºåˆ é™¤è¾¹çš„æ¯”ä¾‹
    noise_std : float
        ç‰¹å¾åŠ æ€§å™ªå£°æ ‡å‡†å·®
    """
    import torch
    import copy
    import numpy as np

    # æ·±æ‹·è´ä¸€ä»½ï¼Œé˜²æ­¢ä¿®æ”¹åŸå›¾
    aug_data = copy.deepcopy(data)

    # ---------- (1) ç‰¹å¾å¢å¼º ----------
    x = aug_data.x.clone()

    # éšæœºmaskéƒ¨åˆ†èŠ‚ç‚¹ç‰¹å¾
    mask = torch.rand_like(x) > feature_drop_prob
    x = x * mask

    # åŠ å™ªå£°ï¼ˆæ¨¡æ‹Ÿæµ‹é‡è¯¯å·®ï¼‰
    noise = noise_std * torch.randn_like(x)
    x = x + noise

    aug_data.x = x

    # ---------- (2) ç»“æ„å¢å¼º ----------
    edge_index = aug_data.edge_index.clone()
    num_edges = edge_index.shape[1]

    # éšæœºåˆ é™¤ä¸€éƒ¨åˆ†è¾¹
    keep_mask = torch.rand(num_edges) > edge_drop_prob
    edge_index = edge_index[:, keep_mask]
    aug_data.edge_index = edge_index

    return aug_data
