{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fca3bf53",
   "metadata": {},
   "source": [
    "# normal_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f3a5e9",
   "metadata": {},
   "source": [
    "## time pyd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddcb61a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·²æ·»åŠ è·¯å¾„ï¼š/home/charles/HZU/Industrial_Software_Testing/Industrial_Software_Testing/my_CIL_V1/GCL_pre_train/KAIST_normal_model_opt\n",
      "âœ… å·²æ·»åŠ  my_libï¼š/home/charles/HZU/Industrial_Software_Testing/Industrial_Software_Testing/my_CIL_V1/GCL_pre_train/KAIST_normal_model_opt/src\n",
      "\n",
      "========== åŠ è½½ train å›¾ï¼ˆå¸¦ label maskï¼‰ ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_936764/2422783891.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_data = torch.load(train_graph_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ§© Graph Data Summary\n",
      "============================================================\n",
      "ğŸ“Š èŠ‚ç‚¹æ•°é‡ (num_nodes): 42000\n",
      "ğŸ“ˆ èŠ‚ç‚¹ç‰¹å¾ç»´åº¦ (num_features): 4\n",
      "ğŸ”— è¾¹æ•°é‡ (num_edges): 8400000\n",
      "ğŸ” è‡ªç¯æ•°é‡ (self-loops): 0\n",
      "ğŸ¯ æ ‡ç­¾ç»´åº¦ (y_dim): torch.Size([42000])\n",
      "\n",
      "ğŸ§¾ Dataå¯¹è±¡åŒ…å«å­—æ®µ: ['train_withlabel_mask', 'edge_index', 'train_nolabel_mask', 'x', 'y']\n",
      "============================================================\n",
      "\n",
      "\n",
      "========== åŠ è½½ val å›¾ ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_936764/2422783891.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  val_data = torch.load(val_graph_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== åŠ è½½ test å›¾ ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_936764/2422783891.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_data = torch.load(test_graph_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ å·²å®Œæˆ train_data.x æ ‡å‡†åŒ–\n",
      "ğŸ¯ å·²å®Œæˆ test_data.x æ ‡å‡†åŒ–\n",
      "ğŸ“Œ å…±ç”Ÿæˆ 42 ä¸ªå­å›¾ batch\n"
     ]
    }
   ],
   "source": [
    "# ================== 1ï¸âƒ£ å¯¼å…¥è·¯å¾„ä¸å‡½æ•° ==================\n",
    "%run ../_init_path.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import subgraph, add_self_loops\n",
    "\n",
    "# === å¯¼å…¥æ¨¡å‹ç»“æ„ ===\n",
    "from models import GraphContrastiveLearner, augment_graph, summarize_graph\n",
    "\n",
    "\n",
    "# ===================== 0ï¸âƒ£ è·¯å¾„è®¾ç½® =====================\n",
    "train_graph_path = \"/home/charles/HZU/Data_processed/my_CIL_V1/KAIST/all_class_morenode/train/pyg/train_graph_with_labelmask.pt\"\n",
    "val_graph_path   = \"/home/charles/HZU/Data_processed/my_CIL_V1/KAIST/all_class_morenode/val/pyg/graph.pt\"\n",
    "test_graph_path  = \"/home/charles/HZU/Data_processed/my_CIL_V1/KAIST/all_class_morenode/test/pyg/graph.pt\"\n",
    "\n",
    "save_dir = \"/home/charles/HZU/Industrial_Software_Testing/Industrial_Software_Testing/my_CIL_V1/GCL_pre_train/KAIST_normal_model_opt/model_save/time_morenode\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# ===================== 1ï¸âƒ£ åŠ è½½å›¾æ•°æ® =====================\n",
    "print(\"\\n========== åŠ è½½ train å›¾ï¼ˆå¸¦ label maskï¼‰ ==========\")\n",
    "train_data = torch.load(train_graph_path)\n",
    "summarize_graph(train_data)\n",
    "\n",
    "print(\"\\n========== åŠ è½½ val å›¾ ==========\")\n",
    "val_data = torch.load(val_graph_path)\n",
    "\n",
    "print(\"\\n========== åŠ è½½ test å›¾ ==========\")\n",
    "test_data = torch.load(test_graph_path)\n",
    "\n",
    "\n",
    "# ===================== 2ï¸âƒ£ å¯¹ train_data.x åš Z-score æ ‡å‡†åŒ– =====================\n",
    "x_mean = train_data.x.mean(dim=0, keepdim=True)\n",
    "x_std  = train_data.x.std(dim=0, keepdim=True) + 1e-6\n",
    "train_data.x = (train_data.x - x_mean) / x_std\n",
    "\n",
    "print(\"ğŸ¯ å·²å®Œæˆ train_data.x æ ‡å‡†åŒ–\")\n",
    "\n",
    "x_mean = test_data.x.mean(dim=0, keepdim=True)\n",
    "x_std  = test_data.x.std(dim=0, keepdim=True) + 1e-6\n",
    "test_data.x = (test_data.x - x_mean) / x_std\n",
    "\n",
    "print(\"ğŸ¯ å·²å®Œæˆ test_data.x æ ‡å‡†åŒ–\")\n",
    "\n",
    "# ===================== 3ï¸âƒ£ æ„é€  batch å­å›¾ =====================\n",
    "batch_size = 1024\n",
    "num_nodes = train_data.num_nodes\n",
    "\n",
    "perm = torch.randperm(num_nodes)\n",
    "\n",
    "batches = []\n",
    "for i in range(0, num_nodes, batch_size):\n",
    "    node_idx = perm[i:i + batch_size]\n",
    "\n",
    "    # ---- æå–å­å›¾ï¼ˆå¿…é¡» CPUï¼‰----\n",
    "    sub_edge_index, _ = subgraph(\n",
    "        node_idx,\n",
    "        train_data.edge_index,\n",
    "        relabel_nodes=True\n",
    "    )\n",
    "\n",
    "    sub_x = train_data.x[node_idx]\n",
    "\n",
    "    # ---------- â­ åŠ å…¥è‡ªç¯ ----------\n",
    "    sub_edge_index, _ = add_self_loops(\n",
    "        sub_edge_index, num_nodes=sub_x.size(0)\n",
    "    )\n",
    "\n",
    "    sub_data = Data(\n",
    "        x=sub_x,\n",
    "        edge_index=sub_edge_index,\n",
    "    )\n",
    "    batches.append(sub_data)\n",
    "\n",
    "print(f\"ğŸ“Œ å…±ç”Ÿæˆ {len(batches)} ä¸ªå­å›¾ batch\")\n",
    "\n",
    "loader = DataLoader(batches, batch_size=1, shuffle=True)\n",
    "\n",
    "\n",
    "# ===================== 4ï¸âƒ£ åˆå§‹åŒ–æ¨¡å‹ =====================\n",
    "in_dim = train_data.x.size(1)\n",
    "hidden_dim = 256\n",
    "out_dim = 256\n",
    "proj_dim = 128\n",
    "tau = 0.5\n",
    "\n",
    "model = GraphContrastiveLearner(in_dim, hidden_dim, out_dim, proj_dim, tau).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbad4f8f",
   "metadata": {},
   "source": [
    "## è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0672d04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== 5ï¸âƒ£ Batch è®­ç»ƒ =====================\n",
    "epochs = 200\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "best_model_path = os.path.join(save_dir, f\"KAIST_normal_pretrain_best.pt\")\n",
    "\n",
    "print(\"\\n================= ğŸš€ å¼€å§‹ Batch å¯¹æ¯”å­¦ä¹ è®­ç»ƒ =================\\n\")\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch_data in loader:\n",
    "        batch_data = batch_data[0].to(device)   # batch_size=1 â†’ å–ç¬¬ 0 ä¸ª\n",
    "\n",
    "        # ---- ç”Ÿæˆä¸¤ä»½å¢å¼ºè§†å›¾ ----\n",
    "        data1 = augment_graph(\n",
    "            batch_data,\n",
    "            feature_drop_prob=0.2,\n",
    "            edge_drop_prob=0.1,\n",
    "            noise_std=0.02\n",
    "        ).to(device)\n",
    "\n",
    "        data2 = augment_graph(\n",
    "            batch_data,\n",
    "            feature_drop_prob=0.2,\n",
    "            edge_drop_prob=0.1,\n",
    "            noise_std=0.02\n",
    "        ).to(device)\n",
    "\n",
    "        # ---- è®¡ç®— InfoNCE å¯¹æ¯”æŸå¤± ----\n",
    "        loss = model.compute_loss(\n",
    "            data1.x, data1.edge_index,\n",
    "            data2.x, data2.edge_index\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # ======== æ—¥å¿—è¾“å‡º ========\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch [{epoch:03d}/{epochs}] | InfoNCE Loss: {total_loss:.4f}\")\n",
    "\n",
    "    # ======== ä¿å­˜å½“å‰æœ€ä¼˜æ¨¡å‹ ========\n",
    "    if total_loss < best_loss:\n",
    "        best_loss = total_loss\n",
    "\n",
    "        torch.save({\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"best_loss\": best_loss,\n",
    "            \"epoch\": epoch,\n",
    "            \"config\": {\n",
    "                \"in_dim\": in_dim,\n",
    "                \"hidden_dim\": hidden_dim,\n",
    "                \"out_dim\": out_dim,\n",
    "                \"proj_dim\": proj_dim,\n",
    "                \"tau\": tau\n",
    "            }\n",
    "        }, best_model_path)\n",
    "\n",
    "        print(f\"ğŸ’¾ [BEST MODEL UPDATED] Epoch {epoch} | Loss={total_loss:.4f}\")\n",
    "\n",
    "\n",
    "# ===================== æœ€ç»ˆæ¨¡å‹ä¿å­˜ =====================\n",
    "final_path = os.path.join(save_dir, f\"KAIST_normal_pretrain_epoch{epochs}.pt\")\n",
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"epoch\": epochs,\n",
    "    \"config\": {\n",
    "        \"in_dim\": in_dim,\n",
    "        \"hidden_dim\": hidden_dim,\n",
    "        \"out_dim\": out_dim,\n",
    "        \"proj_dim\": proj_dim,\n",
    "        \"tau\": tau\n",
    "    }\n",
    "}, final_path)\n",
    "\n",
    "print(f\"\\nğŸ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜è‡³: {final_path}\")\n",
    "print(f\"ğŸ† æœ€ä¼˜æ¨¡å‹å·²ä¿å­˜è‡³: {best_model_path} | best_loss={best_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f936d66",
   "metadata": {},
   "source": [
    "## æ•ˆæœå¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6517358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "#                â­ å• Cellï¼šä¸ä¼šæŠ¥é”™çš„æ¨¡å‹åŠ è½½ + Train/Test 3D å¯è§†åŒ– â­\n",
    "# ======================================================================\n",
    "\n",
    "# ====================== ç¯å¢ƒå¯¼å…¥ ======================\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# ====================== è·¯å¾„ ======================\n",
    "save_dir = \"/home/charles/HZU/Industrial_Software_Testing/Industrial_Software_Testing/my_CIL_V1/GCL_pre_train/KAIST_normal_model_opt/result/time_morenode\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "model_path = \"/home/charles/HZU/Industrial_Software_Testing/Industrial_Software_Testing/my_CIL_V1/GCL_pre_train/KAIST_normal_model_opt/model_save/time_morenode/KAIST_normal_pretrain_best.pt\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ====================== åŠ è½½è®­ç»ƒæ—¶çš„çœŸå®æ¨¡å‹ç»“æ„ ======================\n",
    "from models import GraphContrastiveLearner   \n",
    "\n",
    "# ----- åŠ è½½ checkpoint -----\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "cfg = checkpoint[\"config\"]\n",
    "\n",
    "# ----- æŒ‰è®­ç»ƒæ—¶çš„æ–¹å¼å®ä¾‹åŒ–æ¨¡å‹ï¼ˆä¸ä¼šæŠ¥é”™ ğŸ‘ï¼‰-----\n",
    "model = GraphContrastiveLearner(\n",
    "    in_dim     = cfg[\"in_dim\"],\n",
    "    hidden_dim = cfg[\"hidden_dim\"],\n",
    "    out_dim    = cfg[\"out_dim\"],\n",
    "    proj_dim   = cfg[\"proj_dim\"],\n",
    "    tau        = cfg[\"tau\"] if \"tau\" in cfg else 0.5\n",
    ").to(device)\n",
    "\n",
    "# ----- åŠ è½½æƒé‡ï¼ˆä¸ä¼šæŠ¥é”™ ğŸ‘ï¼‰-----\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.eval()\n",
    "\n",
    "print(\"âœ… ä½¿ç”¨è®­ç»ƒæ—¶çš„åŸå§‹æ¨¡å‹è¯»å–æˆåŠŸï¼ä¸ä¼šæŠ¥é”™\")\n",
    "\n",
    "# ======================================================================\n",
    "#                â­ 1ï¸âƒ£ æå– Train å’Œ Test çš„åµŒå…¥\n",
    "# ======================================================================\n",
    "\n",
    "# ä½ å‰é¢å·²ç»ï¼štrain_data / test_data = torch.load(...)\n",
    "train_data = train_data.to(device)\n",
    "test_data  = test_data.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    _, z_train = model(train_data.x, train_data.edge_index)\n",
    "    _, z_test  = model(test_data.x,  test_data.edge_index)\n",
    "\n",
    "train_emb = z_train.cpu().numpy()\n",
    "test_emb  = z_test.cpu().numpy()\n",
    "\n",
    "train_labels = train_data.y.cpu().numpy() if hasattr(train_data, \"y\") else np.zeros(train_emb.shape[0])\n",
    "test_labels  = test_data.y.cpu().numpy() if hasattr(test_data,  \"y\") else np.zeros(test_emb.shape[0])\n",
    "\n",
    "print(f\"â­ Train Embeddings Shape: {train_emb.shape}\")\n",
    "print(f\"â­ Test  Embeddings Shape: {test_emb.shape}\")\n",
    "\n",
    "# ======================================================================\n",
    "#                â­ 2ï¸âƒ£ 3D UMAP é™ç»´\n",
    "# ======================================================================\n",
    "reducer_train = umap.UMAP(\n",
    "    n_neighbors=10, min_dist=0.1, n_components=3,\n",
    "    metric=\"cosine\", random_state=42\n",
    ")\n",
    "train_umap = reducer_train.fit_transform(train_emb)\n",
    "\n",
    "reducer_test = umap.UMAP(\n",
    "    n_neighbors=10, min_dist=0.1, n_components=3,\n",
    "    metric=\"cosine\", random_state=42\n",
    ")\n",
    "test_umap = reducer_test.fit_transform(test_emb)\n",
    "\n",
    "# ======================================================================\n",
    "#                â­ 3ï¸âƒ£ ç»˜åˆ¶ Train 3D UMAP\n",
    "# ======================================================================\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    train_umap[:,0], train_umap[:,1], train_umap[:,2],\n",
    "    c=train_labels, cmap='tab20', s=8, alpha=0.85\n",
    ")\n",
    "\n",
    "ax.set_title(\"Train Graph Embeddings - 3D UMAP\")\n",
    "ax.set_xlabel(\"UMAP-1\"); ax.set_ylabel(\"UMAP-2\"); ax.set_zlabel(\"UMAP-3\")\n",
    "\n",
    "legend = plt.legend(\n",
    "    *scatter.legend_elements(num=None),\n",
    "    title=\"Labels\", loc=\"center left\", bbox_to_anchor=(1.02, 0.5), fontsize=8\n",
    ")\n",
    "ax.add_artist(legend)\n",
    "\n",
    "plt.tight_layout(rect=[0,0,0.85,1])\n",
    "plt.savefig(os.path.join(save_dir, \"train_umap_3d.png\"), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# ======================================================================\n",
    "#                â­ 4ï¸âƒ£ ç»˜åˆ¶ Test 3D UMAP\n",
    "# ======================================================================\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    test_umap[:,0], test_umap[:,1], test_umap[:,2],\n",
    "    c=test_labels, cmap='tab20', s=8, alpha=0.85\n",
    ")\n",
    "\n",
    "ax.set_title(\"Test Graph Embeddings - 3D UMAP\")\n",
    "ax.set_xlabel(\"UMAP-1\"); ax.set_ylabel(\"UMAP-2\"); ax.set_zlabel(\"UMAP-3\")\n",
    "\n",
    "legend = plt.legend(\n",
    "    *scatter.legend_elements(num=None),\n",
    "    title=\"Labels\", loc=\"center left\", bbox_to_anchor=(1.02, 0.5), fontsize=8\n",
    ")\n",
    "ax.add_artist(legend)\n",
    "\n",
    "plt.tight_layout(rect=[0,0,0.85,1])\n",
    "plt.savefig(os.path.join(save_dir, \"test_umap_3d.png\"), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# ======================================================================\n",
    "#                â­ 5ï¸âƒ£ ä¿å­˜åµŒå…¥\n",
    "# ======================================================================\n",
    "np.save(os.path.join(save_dir, \"train_emb.npy\"), train_emb)\n",
    "np.save(os.path.join(save_dir, \"train_umap_3d.npy\"), train_umap)\n",
    "np.save(os.path.join(save_dir, \"test_emb.npy\"),  test_emb)\n",
    "np.save(os.path.join(save_dir, \"test_umap_3d.npy\"),  test_umap)\n",
    "\n",
    "print(\"\\nğŸ¯ Train / Test 3D UMAP å…¨éƒ¨å®Œæˆå¹¶ä¿å­˜ï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8162661",
   "metadata": {},
   "source": [
    "## ä¸‹æ¸¸è®­ç»ƒ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039a42c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "#        â­ å• Cellï¼šä½¿ç”¨ train_withlabel_mask æ•´å›¾è®­ç»ƒä¸‹æ¸¸åˆ†ç±»å™¨ â­\n",
    "# ======================================================================\n",
    "%run ../_init_path.py\n",
    "from models import GraphContrastiveLearner, DownstreamClassifier\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ======================================================================\n",
    "# 1. ä» encoder æå– h_trainï¼ˆä½ å·²ç»åœ¨å¤–éƒ¨åŠ è½½å¥½ model & train_dataï¼‰\n",
    "# ======================================================================\n",
    "\n",
    "train_data = train_data.to(device)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"ğŸš€ æå–è®­ç»ƒæ•°æ®ç‰¹å¾ï¼ˆEncoder forwardï¼‰...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    h_train, _ = model(train_data.x, train_data.edge_index)\n",
    "\n",
    "h_train = h_train.detach()                   # [N, out_dim]\n",
    "y_all = train_data.y                         # [N]\n",
    "mask = train_data.train_withlabel_mask       # bool mask\n",
    "\n",
    "idx = mask.nonzero(as_tuple=False).view(-1)  # æ ‡è®°æœ‰æ ‡ç­¾çš„æ•°æ®\n",
    "h_labeled = h_train[idx]                     # [num_labeled, out_dim]\n",
    "y_labeled = y_all[idx]                       # [num_labeled]\n",
    "\n",
    "print(f\"ğŸ“Œ æœ‰æ ‡ç­¾æ ·æœ¬æ•°: {h_labeled.shape[0]}\")\n",
    "print(f\"ğŸ“Œ è¡¨å¾ç»´åº¦(out_dim): {h_labeled.shape[1]}\")\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# 2. å®šä¹‰åˆ†ç±»å¤´ï¼ˆå…¨å›¾è®­ç»ƒï¼‰\n",
    "# ======================================================================\n",
    "\n",
    "num_features = h_labeled.size(1)\n",
    "num_classes = int(y_labeled.max().item() + 1)\n",
    "\n",
    "classifier = DownstreamClassifier(\n",
    "    in_dim=num_features,\n",
    "    num_classes=num_classes,\n",
    "    hidden_dim=128\n",
    ").to(device)\n",
    "\n",
    "optimizer = Adam(classifier.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# 3. æ•´å›¾è®­ç»ƒï¼ˆä¸åˆ† batchï¼‰\n",
    "# ======================================================================\n",
    "\n",
    "epochs = 100\n",
    "print(\"\\n================== ğŸ”¥ å¼€å§‹ä¸‹æ¸¸åˆ†ç±»è®­ç»ƒï¼ˆæ•´å›¾ï¼‰ ==================\\n\")\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "\n",
    "    classifier.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    logits = classifier(h_labeled)      # å…¨éƒ¨ labeled æ ·æœ¬ä¸€èµ· forward\n",
    "    loss = F.cross_entropy(logits, y_labeled)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch {epoch:03d}/{epochs} | Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"\\nğŸ ä¸‹æ¸¸çº¿æ€§åˆ†ç±»è®­ç»ƒå®Œæˆï¼ˆæ•´å›¾æ–¹å¼ï¼‰ï¼\")\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# 4. ä¿å­˜åˆ†ç±»å™¨\n",
    "# ======================================================================\n",
    "\n",
    "save_path = \"/home/charles/HZU/Industrial_Software_Testing/Industrial_Software_Testing/my_CIL_V1/GCL_pre_train/KAIST_normal_model_opt/model_save/time_morenode/downstream/downstream_classifier.pt\"\n",
    "\n",
    "torch.save({\n",
    "    \"state_dict\": classifier.state_dict(),\n",
    "    \"in_dim\": num_features,\n",
    "    \"num_classes\": num_classes\n",
    "}, save_path)\n",
    "\n",
    "print(f\"ğŸ’¾ ä¸‹æ¸¸åˆ†ç±»å™¨å·²ä¿å­˜ï¼š{save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663731ab",
   "metadata": {},
   "source": [
    "## æœ€ç»ˆaccæµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dff3945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ æ¨¡å‹è·¯å¾„å·²è®¾ç½®\n",
      "âœ… ä¸Šæ¸¸æ¨¡å‹åŠ è½½æˆåŠŸï¼\n",
      "âœ… ä¸‹æ¸¸åˆ†ç±»å™¨åŠ è½½æˆåŠŸï¼\n",
      "ğŸ“Œ Train/Test å›¾æ•°æ®å·²åŠ è½½è‡³ GPU/CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_936764/2772901260.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(pretrain_path, map_location=device)\n",
      "/tmp/ipykernel_936764/2772901260.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  clf_ckpt = torch.load(classifier_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ å·²æå–ä¸Šæ¸¸ç¼–ç ç‰¹å¾ h_train / h_test\n",
      "\n",
      "ğŸ¯ Train Accuracy (train_withlabel_mask) = 76.14%\n",
      "ğŸ¯ Test Accuracy  (all test nodes) = 74.11%\n",
      "\n",
      "ğŸ å…¨éƒ¨ accuracy è¯„ä¼°å®Œæˆï¼\n",
      "\n",
      "====================== TRAIN METRICS ======================\n",
      "Accuracy : 76.14%\n",
      "Precision: 75.59%\n",
      "Recall   : 76.25%\n",
      "F1-score : 74.53%\n",
      "===========================================================\n",
      "\n",
      "======================= TEST METRICS =======================\n",
      "Accuracy : 74.11%\n",
      "Precision: 72.10%\n",
      "Recall   : 73.93%\n",
      "F1-score : 71.79%\n",
      "===========================================================\n",
      "\n",
      "============== TRAIN WRONG PREDICTIONS ==============\n",
      "âŒ é”™è¯¯æ ·æœ¬æ•°é‡ï¼š3006 / 12600\n",
      "Index    8 | True = 1 | Pred = 12\n",
      "Index   15 | True = 1 | Pred = 11\n",
      "Index   16 | True = 1 | Pred = 12\n",
      "Index   17 | True = 1 | Pred = 14\n",
      "Index   19 | True = 1 | Pred = 11\n",
      "Index   22 | True = 1 | Pred = 11\n",
      "Index   29 | True = 1 | Pred = 12\n",
      "Index   52 | True = 1 | Pred = 14\n",
      "Index   80 | True = 1 | Pred = 14\n",
      "Index   86 | True = 1 | Pred = 11\n",
      "Index  115 | True = 1 | Pred = 11\n",
      "Index  118 | True = 1 | Pred = 12\n",
      "Index  122 | True = 1 | Pred = 11\n",
      "Index  123 | True = 1 | Pred = 12\n",
      "Index  124 | True = 1 | Pred = 12\n",
      "Index  125 | True = 1 | Pred = 11\n",
      "Index  126 | True = 1 | Pred = 11\n",
      "Index  127 | True = 1 | Pred = 12\n",
      "Index  128 | True = 1 | Pred = 12\n",
      "Index  129 | True = 1 | Pred = 12\n",
      "... (å…± 3006 ä¸ªé”™æ ·æœ¬ï¼Œåªæ˜¾ç¤ºå‰ 20 ä¸ª)\n",
      "\n",
      "ğŸ” Train æ¯ç±»é”™è¯¯ç»Ÿè®¡ï¼š(çœŸæ ‡ç­¾ -> é¢„æµ‹æ ‡ç­¾)\n",
      "  1 â†’ 12 : 55 æ¬¡\n",
      "  1 â†’ 11 : 77 æ¬¡\n",
      "  1 â†’ 14 : 78 æ¬¡\n",
      "  1 â†’ 13 : 5 æ¬¡\n",
      "  1 â†’ 8 : 5 æ¬¡\n",
      "  1 â†’ 9 : 2 æ¬¡\n",
      "  1 â†’ 10 : 1 æ¬¡\n",
      "  2 â†’ 4 : 12 æ¬¡\n",
      "  2 â†’ 5 : 1 æ¬¡\n",
      "  2 â†’ 3 : 2 æ¬¡\n",
      "  3 â†’ 4 : 3 æ¬¡\n",
      "  4 â†’ 2 : 2 æ¬¡\n",
      "  5 â†’ 4 : 1 æ¬¡\n",
      "  5 â†’ 2 : 2 æ¬¡\n",
      "  5 â†’ 6 : 1 æ¬¡\n",
      "  7 â†’ 3 : 4 æ¬¡\n",
      "  8 â†’ 7 : 8 æ¬¡\n",
      "  9 â†’ 8 : 5 æ¬¡\n",
      "  9 â†’ 10 : 14 æ¬¡\n",
      "  10 â†’ 9 : 19 æ¬¡\n",
      "  11 â†’ 9 : 7 æ¬¡\n",
      "  11 â†’ 14 : 200 æ¬¡\n",
      "  11 â†’ 1 : 234 æ¬¡\n",
      "  11 â†’ 12 : 205 æ¬¡\n",
      "  11 â†’ 13 : 4 æ¬¡\n",
      "  12 â†’ 11 : 206 æ¬¡\n",
      "  12 â†’ 14 : 216 æ¬¡\n",
      "  12 â†’ 1 : 195 æ¬¡\n",
      "  12 â†’ 13 : 2 æ¬¡\n",
      "  12 â†’ 8 : 1 æ¬¡\n",
      "  13 â†’ 14 : 216 æ¬¡\n",
      "  13 â†’ 12 : 177 æ¬¡\n",
      "  13 â†’ 11 : 156 æ¬¡\n",
      "  13 â†’ 1 : 306 æ¬¡\n",
      "  13 â†’ 8 : 2 æ¬¡\n",
      "  14 â†’ 1 : 173 æ¬¡\n",
      "  14 â†’ 11 : 177 æ¬¡\n",
      "  14 â†’ 12 : 220 æ¬¡\n",
      "  14 â†’ 8 : 10 æ¬¡\n",
      "  14 â†’ 13 : 2 æ¬¡\n",
      "\n",
      "============== TEST WRONG PREDICTIONS ===============\n",
      "âŒ é”™è¯¯æ ·æœ¬æ•°é‡ï¼š3625 / 14000\n",
      "Index    0 | True = 1 | Pred = 11\n",
      "Index    9 | True = 1 | Pred = 12\n",
      "Index   20 | True = 1 | Pred = 11\n",
      "Index   24 | True = 1 | Pred = 12\n",
      "Index   32 | True = 1 | Pred = 14\n",
      "Index   39 | True = 1 | Pred = 12\n",
      "Index   42 | True = 1 | Pred = 12\n",
      "Index   55 | True = 1 | Pred = 11\n",
      "Index   59 | True = 1 | Pred = 14\n",
      "Index   65 | True = 1 | Pred = 12\n",
      "Index   96 | True = 1 | Pred = 12\n",
      "Index   98 | True = 1 | Pred = 13\n",
      "Index  178 | True = 1 | Pred = 13\n",
      "Index  194 | True = 1 | Pred = 12\n",
      "Index  195 | True = 1 | Pred = 14\n",
      "Index  199 | True = 1 | Pred = 12\n",
      "Index  202 | True = 1 | Pred = 13\n",
      "Index  203 | True = 1 | Pred = 14\n",
      "Index  204 | True = 1 | Pred = 12\n",
      "Index  205 | True = 1 | Pred = 11\n",
      "... (å…± 3625 ä¸ªé”™æ ·æœ¬ï¼Œåªæ˜¾ç¤ºå‰ 20 ä¸ª)\n",
      "\n",
      "ğŸ” Test æ¯ç±»é”™è¯¯ç»Ÿè®¡ï¼š(çœŸæ ‡ç­¾ -> é¢„æµ‹æ ‡ç­¾)\n",
      "  1 â†’ 11 : 20 æ¬¡\n",
      "  1 â†’ 12 : 37 æ¬¡\n",
      "  1 â†’ 14 : 41 æ¬¡\n",
      "  1 â†’ 13 : 6 æ¬¡\n",
      "  1 â†’ 8 : 4 æ¬¡\n",
      "  1 â†’ 9 : 6 æ¬¡\n",
      "  1 â†’ 10 : 6 æ¬¡\n",
      "  1 â†’ 2 : 20 æ¬¡\n",
      "  2 â†’ 10 : 1 æ¬¡\n",
      "  2 â†’ 4 : 4 æ¬¡\n",
      "  2 â†’ 5 : 4 æ¬¡\n",
      "  2 â†’ 3 : 18 æ¬¡\n",
      "  4 â†’ 3 : 13 æ¬¡\n",
      "  4 â†’ 2 : 39 æ¬¡\n",
      "  5 â†’ 4 : 7 æ¬¡\n",
      "  5 â†’ 6 : 8 æ¬¡\n",
      "  7 â†’ 6 : 2 æ¬¡\n",
      "  7 â†’ 3 : 14 æ¬¡\n",
      "  7 â†’ 4 : 2 æ¬¡\n",
      "  8 â†’ 7 : 19 æ¬¡\n",
      "  9 â†’ 8 : 20 æ¬¡\n",
      "  9 â†’ 10 : 9 æ¬¡\n",
      "  10 â†’ 9 : 29 æ¬¡\n",
      "  11 â†’ 9 : 10 æ¬¡\n",
      "  11 â†’ 14 : 205 æ¬¡\n",
      "  11 â†’ 1 : 300 æ¬¡\n",
      "  11 â†’ 12 : 295 æ¬¡\n",
      "  11 â†’ 13 : 3 æ¬¡\n",
      "  12 â†’ 14 : 199 æ¬¡\n",
      "  12 â†’ 11 : 251 æ¬¡\n",
      "  12 â†’ 1 : 244 æ¬¡\n",
      "  12 â†’ 13 : 5 æ¬¡\n",
      "  12 â†’ 8 : 7 æ¬¡\n",
      "  13 â†’ 1 : 283 æ¬¡\n",
      "  13 â†’ 14 : 238 æ¬¡\n",
      "  13 â†’ 12 : 292 æ¬¡\n",
      "  13 â†’ 11 : 195 æ¬¡\n",
      "  13 â†’ 8 : 3 æ¬¡\n",
      "  14 â†’ 1 : 269 æ¬¡\n",
      "  14 â†’ 12 : 278 æ¬¡\n",
      "  14 â†’ 11 : 211 æ¬¡\n",
      "  14 â†’ 13 : 8 æ¬¡\n",
      "\n",
      "ğŸ é”™è¯¯æ ·æœ¬ç»Ÿè®¡å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "#    â­ å• Cellï¼šåŠ è½½ä¸Šæ¸¸æ¨¡å‹ + ä¸‹æ¸¸åˆ†ç±»å™¨ï¼Œå¹¶è®¡ç®— Train/Test Accuracy â­\n",
    "# ======================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ====================== æ¨¡å‹è·¯å¾„ ======================\n",
    "pretrain_path = \"/home/charles/HZU/Industrial_Software_Testing/Industrial_Software_Testing/my_CIL_V1/GCL_pre_train/KAIST_normal_model_opt/model_save/time_morenode/KAIST_normal_pretrain_best.pt\"\n",
    "\n",
    "classifier_path = \"/home/charles/HZU/Industrial_Software_Testing/Industrial_Software_Testing/my_CIL_V1/GCL_pre_train/KAIST_normal_model_opt/model_save/time_morenode/downstream/downstream_classifier.pt\"\n",
    "\n",
    "print(\"ğŸ“Œ æ¨¡å‹è·¯å¾„å·²è®¾ç½®\")\n",
    "\n",
    "\n",
    "# ====================== åŠ è½½æ¨¡å‹ç»“æ„ ======================\n",
    "from models import GraphContrastiveLearner, DownstreamClassifier\n",
    "\n",
    "# ------- åŠ è½½ä¸Šæ¸¸ GCL æ¨¡å‹ -------\n",
    "ckpt = torch.load(pretrain_path, map_location=device)\n",
    "cfg = ckpt[\"config\"]\n",
    "\n",
    "model = GraphContrastiveLearner(\n",
    "    in_dim     = cfg[\"in_dim\"],\n",
    "    hidden_dim = cfg[\"hidden_dim\"],\n",
    "    out_dim    = cfg[\"out_dim\"],\n",
    "    proj_dim   = cfg[\"proj_dim\"],\n",
    "    tau        = cfg[\"tau\"] if \"tau\" in cfg else 0.5\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(ckpt[\"model_state_dict\"])   # â­ ä¸ä¼šæŠ¥é”™çš„åŠ è½½æ–¹å¼\n",
    "model.eval()\n",
    "print(\"âœ… ä¸Šæ¸¸æ¨¡å‹åŠ è½½æˆåŠŸï¼\")\n",
    "\n",
    "\n",
    "# ------- åŠ è½½ä¸‹æ¸¸åˆ†ç±»å™¨ -------\n",
    "clf_ckpt = torch.load(classifier_path, map_location=device)\n",
    "in_dim = clf_ckpt[\"in_dim\"]\n",
    "num_classes = clf_ckpt[\"num_classes\"]\n",
    "\n",
    "classifier = DownstreamClassifier(\n",
    "    in_dim=in_dim,\n",
    "    num_classes=num_classes,\n",
    "    hidden_dim=128\n",
    ").to(device)\n",
    "\n",
    "classifier.load_state_dict(clf_ckpt[\"state_dict\"])\n",
    "classifier.eval()\n",
    "print(\"âœ… ä¸‹æ¸¸åˆ†ç±»å™¨åŠ è½½æˆåŠŸï¼\")\n",
    "\n",
    "\n",
    "# ====================== åŠ è½½ Train / Test å›¾ ======================\n",
    "# ä½ åœ¨ notebook ä¸­åº”è¯¥å·²ç»æ‰‹åŠ¨åŠ è½½å¥½äº†ï¼š\n",
    "# train_data = torch.load(...)\n",
    "# test_data = torch.load(...)\n",
    "\n",
    "train_data = train_data.to(device)\n",
    "test_data = test_data.to(device)\n",
    "\n",
    "print(\"ğŸ“Œ Train/Test å›¾æ•°æ®å·²åŠ è½½è‡³ GPU/CPU\")\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "#          â­ 1ï¸âƒ£ æå– Train/Test çš„ GCL encoder è¡¨å¾ h\n",
    "# ======================================================================\n",
    "with torch.no_grad():\n",
    "    h_train, _ = model(train_data.x, train_data.edge_index)\n",
    "    h_test,  _ = model(test_data.x,  test_data.edge_index)\n",
    "\n",
    "print(\"ğŸ”§ å·²æå–ä¸Šæ¸¸ç¼–ç ç‰¹å¾ h_train / h_test\")\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "#          â­ 2ï¸âƒ£ Train Accuracyï¼ˆä»… train_withlabel_maskï¼‰\n",
    "# ======================================================================\n",
    "train_mask = train_data.train_withlabel_mask\n",
    "train_idx = train_mask.nonzero(as_tuple=False).view(-1)\n",
    "\n",
    "h_labeled = h_train[train_idx]\n",
    "y_labeled = train_data.y[train_idx]\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits_train = classifier(h_labeled)\n",
    "    pred_train = logits_train.argmax(dim=1)\n",
    "\n",
    "acc_train = (pred_train == y_labeled).float().mean().item()\n",
    "\n",
    "print(f\"\\nğŸ¯ Train Accuracy (train_withlabel_mask) = {acc_train*100:.2f}%\")\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "#          â­ 3ï¸âƒ£ Test Accuracyï¼ˆå…¨éƒ¨ test èŠ‚ç‚¹ï¼‰\n",
    "# ======================================================================\n",
    "with torch.no_grad():\n",
    "    logits_test = classifier(h_test)\n",
    "    pred_test = logits_test.argmax(dim=1)\n",
    "\n",
    "acc_test = (pred_test == test_data.y).float().mean().item()\n",
    "\n",
    "print(f\"ğŸ¯ Test Accuracy  (all test nodes) = {acc_test*100:.2f}%\")\n",
    "\n",
    "print(\"\\nğŸ å…¨éƒ¨ accuracy è¯„ä¼°å®Œæˆï¼\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# ====================== â­ Train metrics ======================\n",
    "y_true_train = y_labeled.cpu().numpy()\n",
    "y_pred_train = pred_train.cpu().numpy()\n",
    "\n",
    "train_acc  = accuracy_score(y_true_train, y_pred_train)\n",
    "train_prec = precision_score(y_true_train, y_pred_train, average=\"macro\", zero_division=0)\n",
    "train_reca = recall_score(y_true_train, y_pred_train, average=\"macro\", zero_division=0)\n",
    "train_f1   = f1_score(y_true_train, y_pred_train, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(\"\\n====================== TRAIN METRICS ======================\")\n",
    "print(f\"Accuracy : {train_acc*100:.2f}%\")\n",
    "print(f\"Precision: {train_prec*100:.2f}%\")\n",
    "print(f\"Recall   : {train_reca*100:.2f}%\")\n",
    "print(f\"F1-score : {train_f1*100:.2f}%\")\n",
    "print(\"===========================================================\\n\")\n",
    "\n",
    "\n",
    "# ====================== â­ Test metrics ======================\n",
    "y_true_test = test_data.y.cpu().numpy()\n",
    "y_pred_test = pred_test.cpu().numpy()\n",
    "\n",
    "test_acc  = accuracy_score(y_true_test, y_pred_test)\n",
    "test_prec = precision_score(y_true_test, y_pred_test, average=\"macro\", zero_division=0)\n",
    "test_reca = recall_score(y_true_test, y_pred_test, average=\"macro\", zero_division=0)\n",
    "test_f1   = f1_score(y_true_test, y_pred_test, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(\"======================= TEST METRICS =======================\")\n",
    "print(f\"Accuracy : {test_acc*100:.2f}%\")\n",
    "print(f\"Precision: {test_prec*100:.2f}%\")\n",
    "print(f\"Recall   : {test_reca*100:.2f}%\")\n",
    "print(f\"F1-score : {test_f1*100:.2f}%\")\n",
    "print(\"===========================================================\\n\")\n",
    "# ======================================================================\n",
    "#          â­ 4ï¸âƒ£ ç»Ÿè®¡é¢„æµ‹é”™è¯¯çš„æ ·æœ¬ï¼ˆçœŸå®æ ‡ç­¾ vs é¢„æµ‹æ ‡ç­¾ï¼‰\n",
    "# ======================================================================\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# ========== Train é”™è¯¯æ ·æœ¬ ==========\n",
    "wrong_train_idx = np.where(y_pred_train != y_true_train)[0]\n",
    "\n",
    "print(\"============== TRAIN WRONG PREDICTIONS ==============\")\n",
    "print(f\"âŒ é”™è¯¯æ ·æœ¬æ•°é‡ï¼š{len(wrong_train_idx)} / {len(y_true_train)}\")\n",
    "\n",
    "# æ‰“å°å‰ 20 ä¸ªé”™è¯¯æ ·æœ¬ï¼ˆé¿å…å¤ªé•¿ï¼‰\n",
    "max_show = 20\n",
    "for i in wrong_train_idx[:max_show]:\n",
    "    print(f\"Index {i:4d} | True = {y_true_train[i]} | Pred = {y_pred_train[i]}\")\n",
    "if len(wrong_train_idx) > max_show:\n",
    "    print(f\"... (å…± {len(wrong_train_idx)} ä¸ªé”™æ ·æœ¬ï¼Œåªæ˜¾ç¤ºå‰ {max_show} ä¸ª)\")\n",
    "\n",
    "# æ¯ç±»é”™è¯¯ç»Ÿè®¡\n",
    "train_wrong_pairs = [(int(y_true_train[i]), int(y_pred_train[i])) for i in wrong_train_idx]\n",
    "train_wrong_count = Counter(train_wrong_pairs)\n",
    "\n",
    "print(\"\\nğŸ” Train æ¯ç±»é”™è¯¯ç»Ÿè®¡ï¼š(çœŸæ ‡ç­¾ -> é¢„æµ‹æ ‡ç­¾)\")\n",
    "for (t, p), cnt in train_wrong_count.items():\n",
    "    print(f\"  {t} â†’ {p} : {cnt} æ¬¡\")\n",
    "\n",
    "\n",
    "# ========== Test é”™è¯¯æ ·æœ¬ ==========\n",
    "wrong_test_idx = np.where(y_pred_test != y_true_test)[0]\n",
    "\n",
    "print(\"\\n============== TEST WRONG PREDICTIONS ===============\")\n",
    "print(f\"âŒ é”™è¯¯æ ·æœ¬æ•°é‡ï¼š{len(wrong_test_idx)} / {len(y_true_test)}\")\n",
    "\n",
    "for i in wrong_test_idx[:max_show]:\n",
    "    print(f\"Index {i:4d} | True = {y_true_test[i]} | Pred = {y_pred_test[i]}\")\n",
    "if len(wrong_test_idx) > max_show:\n",
    "    print(f\"... (å…± {len(wrong_test_idx)} ä¸ªé”™æ ·æœ¬ï¼Œåªæ˜¾ç¤ºå‰ {max_show} ä¸ª)\")\n",
    "\n",
    "# æ¯ç±»é”™è¯¯ç»Ÿè®¡\n",
    "test_wrong_pairs = [(int(y_true_test[i]), int(y_pred_test[i])) for i in wrong_test_idx]\n",
    "test_wrong_count = Counter(test_wrong_pairs)\n",
    "\n",
    "print(\"\\nğŸ” Test æ¯ç±»é”™è¯¯ç»Ÿè®¡ï¼š(çœŸæ ‡ç­¾ -> é¢„æµ‹æ ‡ç­¾)\")\n",
    "for (t, p), cnt in test_wrong_count.items():\n",
    "    print(f\"  {t} â†’ {p} : {cnt} æ¬¡\")\n",
    "\n",
    "print(\"\\nğŸ é”™è¯¯æ ·æœ¬ç»Ÿè®¡å®Œæˆï¼\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
