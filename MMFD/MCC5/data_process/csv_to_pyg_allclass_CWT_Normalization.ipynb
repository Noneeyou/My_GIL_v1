{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0823e6dc",
   "metadata": {},
   "source": [
    "### è®­ç»ƒé›†ã€æµ‹è¯•é›†ã€éªŒè¯é›†åˆ’åˆ†ï¼Œå¦å­˜ä¸ºæ–°çš„csvæ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47291c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åŠ è½½æ•°æ®ï¼š /home/charles/HZU/Data_processed/HSML/MCC5/mcc5_speed_10Nm_1000rpm_raw.csv\n",
      "æ•°æ®åŠ è½½æˆåŠŸï¼Œå…± 1000000 æ¡è®°å½•\n",
      "æ‰€æœ‰æ•°æ®é›†å·²ä¿å­˜ï¼ˆä¿æŒåŸé¡ºåºï¼Œå·²å»é™¤æœ€åä¸€åˆ—ï¼‰ã€‚\n",
      "æ—¥å¿—å†™å…¥å®Œæˆã€‚\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ============= 1. è·¯å¾„è®¾ç½® =============\n",
    "root_dir = \"/home/charles/HZU/Data_processed/HSML/MCC5/\"\n",
    "csv_path = \"/home/charles/HZU/Data_processed/HSML/MCC5/mcc5_speed_10Nm_1000rpm_raw.csv\"\n",
    "\n",
    "print(\"åŠ è½½æ•°æ®ï¼š\", csv_path)\n",
    "\n",
    "train_dir = os.path.join(root_dir, \"train\")\n",
    "val_dir = os.path.join(root_dir, \"val\")\n",
    "test_dir = os.path.join(root_dir, \"test\")\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# ============= 2. è¯»å–æ•°æ® =============\n",
    "df = pd.read_csv(csv_path)\n",
    "print(f\"æ•°æ®åŠ è½½æˆåŠŸï¼Œå…± {len(df)} æ¡è®°å½•\")\n",
    "\n",
    "# è®°å½•åŸå§‹ç´¢å¼•é¡ºåº\n",
    "original_index = df.index.to_numpy()\n",
    "\n",
    "# ============= 3. è®¾ç½®åˆ’åˆ†æ¯”ä¾‹ =============\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.3\n",
    "total = len(df)\n",
    "\n",
    "# ============= 4. éšæœºæŠ½å–ç´¢å¼•ï¼Œä¸æ‰“ä¹±é¡ºåº =============\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# éšæœºé‡‡æ ·ï¼Œä½†ä¸æ”¹å˜åŸå§‹é¡ºåº\n",
    "all_indices = np.arange(total)\n",
    "rng.shuffle(all_indices)\n",
    "\n",
    "train_end = int(total * train_ratio)\n",
    "val_end = train_end + int(total * val_ratio)\n",
    "\n",
    "train_idx = np.sort(all_indices[:train_end])\n",
    "val_idx = np.sort(all_indices[train_end:val_end])\n",
    "test_idx = np.sort(all_indices[val_end:])\n",
    "\n",
    "# ============= 5. ä¿æŒåŸé¡ºåºæŠ½å–æ•°æ® =============\n",
    "train_df = df.loc[train_idx].copy()\n",
    "val_df = df.loc[val_idx].copy()\n",
    "test_df = df.loc[test_idx].copy()\n",
    "\n",
    "# # ============= 6. åˆ é™¤æœ€åä¸€åˆ—ï¼ˆsource_fileï¼‰ =============\n",
    "# last_col = df.columns[-1]\n",
    "# print(f\"ç§»é™¤æœ€åä¸€åˆ—ï¼š{last_col}\")\n",
    "\n",
    "# train_df = train_df.iloc[:, :-1]\n",
    "# val_df = val_df.iloc[:, :-1]\n",
    "# test_df = test_df.iloc[:, :-1]\n",
    "\n",
    "# ============= 7. ä¿å­˜ CSV =============\n",
    "train_df.to_csv(os.path.join(train_dir, \"train.csv\"), index=False)\n",
    "val_df.to_csv(os.path.join(val_dir, \"val.csv\"), index=False)\n",
    "test_df.to_csv(os.path.join(test_dir, \"test.csv\"), index=False)\n",
    "\n",
    "print(\"æ‰€æœ‰æ•°æ®é›†å·²ä¿å­˜ï¼ˆä¿æŒåŸé¡ºåºï¼Œå·²å»é™¤æœ€åä¸€åˆ—ï¼‰ã€‚\")\n",
    "\n",
    "# ============= 8. ä¿å­˜æ—¥å¿— =============\n",
    "log_path = os.path.join(root_dir, \"split_log.txt\")\n",
    "with open(log_path, \"w\") as f:\n",
    "    f.write(\"KAIST all_class æ•°æ®é›†éšæœºåˆ’åˆ†æ—¥å¿—ï¼ˆä¿æŒåŸé¡ºåº+å¿½ç•¥æœ€åä¸€åˆ—ï¼‰\\n\\n\")\n",
    "    f.write(f\"æ€»æ ·æœ¬æ•°: {len(df)}\\n\")\n",
    "    f.write(f\"Train: {len(train_df)}\\n\")\n",
    "    f.write(f\"Val:   {len(val_df)}\\n\")\n",
    "    f.write(f\"Test:  {len(test_df)}\\n\\n\")\n",
    "    f.write(\"åˆ’åˆ†æ¯”ä¾‹:\\n\")\n",
    "    f.write(f\"train_ratio = {train_ratio}\\n\")\n",
    "    f.write(f\"val_ratio   = {val_ratio}\\n\")\n",
    "    f.write(f\"test_ratio  = {test_ratio}\\n\")\n",
    "\n",
    "print(\"æ—¥å¿—å†™å…¥å®Œæˆã€‚\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05fbee1",
   "metadata": {},
   "source": [
    "### CWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6378d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== TRAIN ====================\n",
      "Loading: /home/charles/HZU/Data_processed/HSML/MCC5/train/train.csv\n",
      "Total samples: 600000\n",
      "Windows: 2342\n",
      "Feature dim: 186\n",
      "Saved: /home/charles/HZU/Data_processed/HSML/MCC5/train/train_CWT.csv\n",
      "\n",
      "==================== VAL ====================\n",
      "Loading: /home/charles/HZU/Data_processed/HSML/MCC5/val/val.csv\n",
      "Total samples: 100000\n",
      "Windows: 389\n",
      "Feature dim: 186\n",
      "Saved: /home/charles/HZU/Data_processed/HSML/MCC5/val/val_CWT.csv\n",
      "\n",
      "==================== TEST ====================\n",
      "Loading: /home/charles/HZU/Data_processed/HSML/MCC5/test/test.csv\n",
      "Total samples: 300000\n",
      "Windows: 1170\n",
      "Feature dim: 186\n",
      "Saved: /home/charles/HZU/Data_processed/HSML/MCC5/test/test_CWT.csv\n",
      "\n",
      "ğŸ‰ MCC5 CWT å¤„ç†å®Œæˆï¼ˆtrain / val / testï¼‰\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pywt\n",
    "\n",
    "# ======================================================\n",
    "# è·¯å¾„\n",
    "# ======================================================\n",
    "\n",
    "paths = {\n",
    "    \"train\": \"/home/charles/HZU/Data_processed/HSML/MCC5/train/train.csv\",\n",
    "    \"val\":   \"/home/charles/HZU/Data_processed/HSML/MCC5/val/val.csv\",\n",
    "    \"test\":  \"/home/charles/HZU/Data_processed/HSML/MCC5/test/test.csv\",\n",
    "}\n",
    "\n",
    "# ======================================================\n",
    "# MCC5 é€šé“å®šä¹‰\n",
    "# ======================================================\n",
    "\n",
    "VIB_CHANNELS = [\n",
    "    \"motor_vibration_x\",\n",
    "    \"motor_vibration_y\",\n",
    "    \"motor_vibration_z\",\n",
    "    \"gearbox_vibration_x\",\n",
    "    \"gearbox_vibration_y\",\n",
    "    \"gearbox_vibration_z\",\n",
    "]\n",
    "\n",
    "COND_CHANNELS = [\"speed\", \"torque\"]\n",
    "LABEL_COL = \"class_id\"\n",
    "\n",
    "# ======================================================\n",
    "# å‚æ•°\n",
    "# ======================================================\n",
    "\n",
    "WINDOW = 512\n",
    "STEP   = 256\n",
    "\n",
    "WIDTHS = np.arange(1, 32)\n",
    "WAVELET = \"morl\"\n",
    "\n",
    "# ======================================================\n",
    "# Z-score\n",
    "# ======================================================\n",
    "\n",
    "def normalize_signal(sig):\n",
    "    mean = sig.mean(axis=0, keepdims=True)\n",
    "    std  = sig.std(axis=0, keepdims=True) + 1e-8\n",
    "    return (sig - mean) / std\n",
    "\n",
    "# ======================================================\n",
    "# å¤„ç†å‡½æ•°\n",
    "# ======================================================\n",
    "\n",
    "def process_csv(split_name, csv_path):\n",
    "\n",
    "    print(f\"\\n==================== {split_name.upper()} ====================\")\n",
    "    print(\"Loading:\", csv_path)\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    X_raw = df[VIB_CHANNELS].values\n",
    "    speed = df[\"speed\"].values\n",
    "    torque = df[\"torque\"].values\n",
    "    y = df[LABEL_COL].values\n",
    "\n",
    "    N = len(df)\n",
    "    print(\"Total samples:\", N)\n",
    "\n",
    "    # -------------------------\n",
    "    # æŒ¯åŠ¨å½’ä¸€åŒ–\n",
    "    # -------------------------\n",
    "    X = normalize_signal(X_raw)\n",
    "\n",
    "    cwt_rows = []\n",
    "    window_labels = []\n",
    "    window_speed = []\n",
    "    window_torque = []\n",
    "    window_starts = []\n",
    "\n",
    "    # -------------------------\n",
    "    # æ»‘çª— + CWT\n",
    "    # -------------------------\n",
    "\n",
    "    for start in range(0, N - WINDOW + 1, STEP):\n",
    "\n",
    "        chunk = X[start:start+WINDOW]\n",
    "        chunk_labels = y[start:start+WINDOW]\n",
    "\n",
    "        # ä¼—æ•°æ ‡ç­¾\n",
    "        u, c = np.unique(chunk_labels, return_counts=True)\n",
    "        win_label = u[np.argmax(c)]\n",
    "\n",
    "        win_feat = []\n",
    "\n",
    "        for ch in range(len(VIB_CHANNELS)):\n",
    "\n",
    "            sig = chunk[:, ch]\n",
    "\n",
    "            cwt_mat, _ = pywt.cwt(sig, WIDTHS, WAVELET)\n",
    "            cwt_abs = np.abs(cwt_mat)\n",
    "\n",
    "            cwt_mean = cwt_abs.mean(axis=1)\n",
    "\n",
    "            win_feat.extend(cwt_mean.tolist())\n",
    "\n",
    "        cwt_rows.append(win_feat)\n",
    "        window_labels.append(win_label)\n",
    "        window_speed.append(speed[start:start+WINDOW].mean())\n",
    "        window_torque.append(torque[start:start+WINDOW].mean())\n",
    "        window_starts.append(start)\n",
    "\n",
    "    # -------------------------\n",
    "    # è¾“å‡º\n",
    "    # -------------------------\n",
    "\n",
    "    cwt_rows = np.array(cwt_rows)\n",
    "    scale_dim = len(WIDTHS)\n",
    "\n",
    "    print(\"Windows:\", len(cwt_rows))\n",
    "    print(\"Feature dim:\", cwt_rows.shape[1])\n",
    "\n",
    "    cols = []\n",
    "    for ch in range(len(VIB_CHANNELS)):\n",
    "        for s in range(scale_dim):\n",
    "            cols.append(f\"ch{ch}_scale{s}\")\n",
    "\n",
    "    df_out = pd.DataFrame(cwt_rows, columns=cols)\n",
    "\n",
    "    df_out.insert(0, \"window_start\", window_starts)\n",
    "    df_out.insert(1, \"speed\", window_speed)\n",
    "    df_out.insert(2, \"torque\", window_torque)\n",
    "    df_out[\"label\"] = window_labels\n",
    "\n",
    "    save_path = os.path.join(os.path.dirname(csv_path), f\"{split_name}_CWT.csv\")\n",
    "    df_out.to_csv(save_path, index=False)\n",
    "\n",
    "    print(\"Saved:\", save_path)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# æ‰§è¡Œ\n",
    "# ======================================================\n",
    "\n",
    "for name, path in paths.items():\n",
    "    process_csv(name, path)\n",
    "\n",
    "print(\"\\nğŸ‰ MCC5 CWT å¤„ç†å®Œæˆï¼ˆtrain / val / testï¼‰\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f801c064",
   "metadata": {},
   "source": [
    "### mixed_data->pyg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47219ccb",
   "metadata": {},
   "source": [
    "#### æ—¶é—´é‚»ç‚¹å»ºå›¾"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec29620",
   "metadata": {},
   "source": [
    "##### CWTæ•°æ®å»ºå›¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7c3d6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·²æ·»åŠ è·¯å¾„ï¼š/home/charles/HZU/Industrial_Software_Testing/Industrial_Software_Testing/my_CIL_V1/data_process/KAIST\n",
      "âœ… å·²æ·»åŠ  my_libï¼š/home/charles/HZU/Industrial_Software_Testing/Industrial_Software_Testing/my_CIL_V1/data_process/KAIST/my_lib\n",
      "\n",
      "ğŸš€ å¼€å§‹æ„å»º train å›¾ç»“æ„...\n",
      "ğŸ“ pyg ä¿å­˜ç›®å½•: /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/KAIST_CWT/normalization/train/CWT_pyg\n",
      "âœ… å›¾ç»“æ„æ„å»ºå®Œæˆï¼Œå…± 1639 ä¸ªèŠ‚ç‚¹ï¼Œ16390 æ¡æ— å‘è¾¹\n",
      "ğŸ“ nodes.csv: /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/KAIST_CWT/normalization/train/CWT_pyg/nodes.csv\n",
      "ğŸ“ edges.csv: /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/KAIST_CWT/normalization/train/CWT_pyg/edges.csv\n",
      "ğŸ“ graph.pt : /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/KAIST_CWT/normalization/train/CWT_pyg/graph.pt\n",
      "ğŸ§© ç‰¹å¾ç»´åº¦: 124 (å·²è‡ªåŠ¨å¿½ç•¥é¦–åˆ—ä¸æ ‡ç­¾åˆ—)\n",
      "   ğŸ“„ nodes_csv: /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/KAIST_CWT/normalization/train/CWT_pyg/nodes.csv\n",
      "   ğŸ“„ edges_csv: /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/KAIST_CWT/normalization/train/CWT_pyg/edges.csv\n",
      "   ğŸ“¦ graph_pt : /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/KAIST_CWT/normalization/train/CWT_pyg/graph.pt\n",
      "âœ… train å›¾æ„å»ºå®Œæˆã€‚\n",
      "\n",
      "ğŸš€ å¼€å§‹æ„å»º val å›¾ç»“æ„...\n",
      "ğŸ“ pyg ä¿å­˜ç›®å½•: /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/KAIST_CWT/normalization/val/CWT_pyg\n",
      "âœ… å›¾ç»“æ„æ„å»ºå®Œæˆï¼Œå…± 272 ä¸ªèŠ‚ç‚¹ï¼Œ2720 æ¡æ— å‘è¾¹\n",
      "ğŸ“ nodes.csv: /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/KAIST_CWT/normalization/val/CWT_pyg/nodes.csv\n",
      "ğŸ“ edges.csv: /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/KAIST_CWT/normalization/val/CWT_pyg/edges.csv\n",
      "ğŸ“ graph.pt : /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/KAIST_CWT/normalization/val/CWT_pyg/graph.pt\n",
      "ğŸ§© ç‰¹å¾ç»´åº¦: 124 (å·²è‡ªåŠ¨å¿½ç•¥é¦–åˆ—ä¸æ ‡ç­¾åˆ—)\n",
      "   ğŸ“„ nodes_csv: /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/KAIST_CWT/normalization/val/CWT_pyg/nodes.csv\n",
      "   ğŸ“„ edges_csv: /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/KAIST_CWT/normalization/val/CWT_pyg/edges.csv\n",
      "   ğŸ“¦ graph_pt : /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/KAIST_CWT/normalization/val/CWT_pyg/graph.pt\n",
      "âœ… val å›¾æ„å»ºå®Œæˆã€‚\n",
      "\n",
      "ğŸš€ å¼€å§‹æ„å»º test å›¾ç»“æ„...\n",
      "ğŸ“ pyg ä¿å­˜ç›®å½•: /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/KAIST_CWT/normalization/test/CWT_pyg\n",
      "âœ… å›¾ç»“æ„æ„å»ºå®Œæˆï¼Œå…± 819 ä¸ªèŠ‚ç‚¹ï¼Œ8190 æ¡æ— å‘è¾¹\n",
      "ğŸ“ nodes.csv: /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/KAIST_CWT/normalization/test/CWT_pyg/nodes.csv\n",
      "ğŸ“ edges.csv: /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/KAIST_CWT/normalization/test/CWT_pyg/edges.csv\n",
      "ğŸ“ graph.pt : /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/KAIST_CWT/normalization/test/CWT_pyg/graph.pt\n",
      "ğŸ§© ç‰¹å¾ç»´åº¦: 124 (å·²è‡ªåŠ¨å¿½ç•¥é¦–åˆ—ä¸æ ‡ç­¾åˆ—)\n",
      "   ğŸ“„ nodes_csv: /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/KAIST_CWT/normalization/test/CWT_pyg/nodes.csv\n",
      "   ğŸ“„ edges_csv: /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/KAIST_CWT/normalization/test/CWT_pyg/edges.csv\n",
      "   ğŸ“¦ graph_pt : /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/KAIST_CWT/normalization/test/CWT_pyg/graph.pt\n",
      "âœ… test å›¾æ„å»ºå®Œæˆã€‚\n",
      "\n",
      "ğŸ‰ ä¸‰ä¸ªæ•°æ®é›† (train/val/test) çš„å›¾å·²ç»å…¨éƒ¨ç‹¬ç«‹æ„å»ºå®Œæ¯•ï¼\n"
     ]
    }
   ],
   "source": [
    "# ================== 1ï¸âƒ£ å¯¼å…¥è·¯å¾„ä¸å‡½æ•° ==================\n",
    "%run ../_init_path.py\n",
    "from build_pyg_data import build_local_temporal_graph   # â˜… ä½ è¦ç”¨çš„å‡½æ•°\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# ================== 2ï¸âƒ£ æ ¹ç›®å½• ==================\n",
    "root_dir = \"/home/charles/HZU/Data_processed/my_CIL_V1/KAIST/KAIST_CWT/normalization\"\n",
    "\n",
    "splits = {\n",
    "    \"train\": os.path.join(root_dir, \"train/train_CWT.csv\"),\n",
    "    \"val\":   os.path.join(root_dir, \"val/val_CWT.csv\"),\n",
    "    \"test\":  os.path.join(root_dir, \"test/test_CWT.csv\"),\n",
    "}\n",
    "\n",
    "# ================== 3ï¸âƒ£ å»ºå›¾å‚æ•°å¯è°ƒ ==================\n",
    "num_edges = 10     # æ—¶é—´ç›¸é‚» KNN æ•°ï¼ˆä½ è‡ªå·±å®šï¼‰\n",
    "\n",
    "# ================== 4ï¸âƒ£ åˆ†åˆ«ä¸ºä¸‰ä¸ªé›†å»ºå›¾ ==================\n",
    "for split_name, csv_path in splits.items():\n",
    "\n",
    "    print(f\"\\nğŸš€ å¼€å§‹æ„å»º {split_name} å›¾ç»“æ„...\")\n",
    "    assert os.path.exists(csv_path), f\"âŒ CSV æ–‡ä»¶ä¸å­˜åœ¨ï¼š{csv_path}\"\n",
    "\n",
    "    # === ä¿å­˜è·¯å¾„ï¼štrain/pyg/ã€val/pyg/ã€test/pyg/ ===\n",
    "    pyg_dir = os.path.join(os.path.dirname(csv_path), \"CWT_pyg\")\n",
    "    os.makedirs(pyg_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"ğŸ“ pyg ä¿å­˜ç›®å½•: {pyg_dir}\")\n",
    "\n",
    "    # === è°ƒç”¨æœ¬åœ°æ—¶åºå»ºå›¾å‡½æ•° ===\n",
    "    nodes_csv, edges_csv, graph_pt = build_local_temporal_graph(\n",
    "        csv_path=csv_path,\n",
    "        save_dir=pyg_dir,\n",
    "        num_edges=num_edges\n",
    "    )\n",
    "\n",
    "    print(f\"   ğŸ“„ nodes_csv: {nodes_csv}\")\n",
    "    print(f\"   ğŸ“„ edges_csv: {edges_csv}\")\n",
    "    print(f\"   ğŸ“¦ graph_pt : {graph_pt}\")\n",
    "\n",
    "    print(f\"âœ… {split_name} å›¾æ„å»ºå®Œæˆã€‚\")\n",
    "\n",
    "print(\"\\nğŸ‰ ä¸‰ä¸ªæ•°æ®é›† (train/val/test) çš„å›¾å·²ç»å…¨éƒ¨ç‹¬ç«‹æ„å»ºå®Œæ¯•ï¼\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c5ad72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== TRAIN ====================\n",
      "Loading: /home/charles/HZU/Data_processed/HSML/MCC5/train/train.csv\n",
      "Total samples: 60000\n",
      "Windows: 233\n",
      "Feature dim: 186\n",
      "Saved: /home/charles/HZU/Data_processed/HSML/MCC5/train/train_CWT.csv\n",
      "\n",
      "==================== VAL ====================\n",
      "Loading: /home/charles/HZU/Data_processed/HSML/MCC5/val/val.csv\n",
      "Total samples: 10000\n",
      "Windows: 38\n",
      "Feature dim: 186\n",
      "Saved: /home/charles/HZU/Data_processed/HSML/MCC5/val/val_CWT.csv\n",
      "\n",
      "==================== TEST ====================\n",
      "Loading: /home/charles/HZU/Data_processed/HSML/MCC5/test/test.csv\n",
      "Total samples: 30000\n",
      "Windows: 116\n",
      "Feature dim: 186\n",
      "Saved: /home/charles/HZU/Data_processed/HSML/MCC5/test/test_CWT.csv\n",
      "\n",
      "ğŸ‰ MCC5 CWT å¤„ç†å®Œæˆï¼ˆtrain / val / testï¼‰\n"
     ]
    }
   ],
   "source": [
    "# ================== 1ï¸âƒ£ å¯¼å…¥è·¯å¾„ä¸å‡½æ•° ==================\n",
    "%run ../_init_path.py\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# ================== 2ï¸âƒ£ è¯»å– train å›¾ ==================\n",
    "train_graph_path = \"/home/charles/HZU/Data_processed/my_CIL_V1/KAIST/KAIST_CWT/normalization/train/CWT_pyg/graph.pt\"\n",
    "assert os.path.exists(train_graph_path), f\"âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼š{train_graph_path}\"\n",
    "\n",
    "print(f\"ğŸ“Œ åŠ è½½ train å›¾ï¼š{train_graph_path}\")\n",
    "data = torch.load(train_graph_path)\n",
    "\n",
    "total_nodes = data.x.size(0)\n",
    "print(f\"èŠ‚ç‚¹æ•° = {total_nodes}\")\n",
    "\n",
    "# ================== 3ï¸âƒ£ è®¾ç½®æ¯”ä¾‹ ==================\n",
    "train_label_ratio = 0.3   # 30% èŠ‚ç‚¹ä¸º train_withlabel\n",
    "\n",
    "num_withlabel = int(total_nodes * train_label_ratio)\n",
    "num_nolabel = total_nodes - num_withlabel\n",
    "\n",
    "print(f\"ğŸ‘‰ æœ‰æ ‡ç­¾èŠ‚ç‚¹ï¼š{num_withlabel}  | æ— æ ‡ç­¾èŠ‚ç‚¹ï¼š{num_nolabel}\")\n",
    "\n",
    "# ================== 4ï¸âƒ£ éšæœºç”Ÿæˆ maskï¼ˆä¿æŒå¯å¤ç°ï¼‰ ==================\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "all_indices = np.arange(total_nodes)\n",
    "rng.shuffle(all_indices)\n",
    "\n",
    "withlabel_idx = all_indices[:num_withlabel]\n",
    "nolabel_idx   = all_indices[num_withlabel:]\n",
    "\n",
    "# åˆ›å»º mask\n",
    "train_withlabel_mask = np.zeros(total_nodes, dtype=bool)\n",
    "train_nolabel_mask   = np.zeros(total_nodes, dtype=bool)\n",
    "\n",
    "train_withlabel_mask[withlabel_idx] = True\n",
    "train_nolabel_mask[nolabel_idx] = True\n",
    "\n",
    "# ================== 5ï¸âƒ£ æ·»åŠ åˆ° Data å¯¹è±¡ ==================\n",
    "data.train_withlabel_mask = torch.tensor(train_withlabel_mask)\n",
    "data.train_nolabel_mask   = torch.tensor(train_nolabel_mask)\n",
    "\n",
    "print(\"âœ… æ©ç æ·»åŠ å®Œæˆï¼š\")\n",
    "print(f\"  train_withlabel_mask.sum() = {int(data.train_withlabel_mask.sum())}\")\n",
    "print(f\"  train_nolabel_mask.sum()   = {int(data.train_nolabel_mask.sum())}\")\n",
    "\n",
    "# ================== 6ï¸âƒ£ ä¿å­˜æ–°çš„å›¾ç»“æ„ ==================\n",
    "save_path = os.path.join(\n",
    "    os.path.dirname(train_graph_path),\n",
    "    \"train_graph_with_labelmask.pt\"\n",
    ")\n",
    "\n",
    "torch.save(data, save_path)\n",
    "print(f\"ğŸ‰ æ–°å›¾å·²ä¿å­˜ä¸ºï¼š{save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
