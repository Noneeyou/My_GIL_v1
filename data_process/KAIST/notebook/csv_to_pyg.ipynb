{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72fb9667",
   "metadata": {},
   "source": [
    "# è®¾ç½®æ•°æ®æ–‡ä»¶å­˜æ”¾æ ¹ç›®å½•ï¼ˆä¸ç›´æ¥æ”¾åœ¨è¯¥é¡¹ç›®ä¸­ï¼Œè¯¥é¡¹ç›®æœ‰githubä»“åº“ï¼Œé¿å…å¤§å†…å­˜æ•°æ®å½±å“ä»£ç æ¨é€ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc098e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_file_adr = \"/home/charles/HZU/Data_processed/my_CIL_V1/KAIST\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601b3c79",
   "metadata": {},
   "source": [
    "# å»ºç«‹æ˜ å°„è¡¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a7ea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ========================\n",
    "# è·¯å¾„é…ç½®\n",
    "# ========================\n",
    "# boot_file_adr = \"/home/charles/HZU/Data_processed/my_CIL_V1/KAIST\"\n",
    "raw_csv_dir = os.path.join(boot_file_adr, \"raw_csv\")\n",
    "save_dir = os.path.join(boot_file_adr, \"mapping_table\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "save_path = os.path.join(save_dir, \"KAIST_vibration_mapping.csv\")\n",
    "\n",
    "# ========================\n",
    "# è·å–æ–‡ä»¶åˆ—è¡¨\n",
    "# ========================\n",
    "csv_files = sorted([f for f in os.listdir(raw_csv_dir) if f.endswith(\".csv\")])\n",
    "\n",
    "# ========================\n",
    "# æ ‡ç­¾æ˜ å°„ï¼ˆNormal=1ï¼Œä¸åŒè½¬é€Ÿ/æ•…éšœç‹¬ç«‹ç¼–å·ï¼‰\n",
    "# ========================\n",
    "mapping_rules = {\n",
    "    \"Normal\": 1,\n",
    "    \"BPFI_03\": 2,\n",
    "    \"BPFI_10\": 3,\n",
    "    \"BPFI_30\": 4,\n",
    "    \"BPFO_03\": 5,\n",
    "    \"BPFO_10\": 6,\n",
    "    \"BPFO_30\": 7,\n",
    "    \"Misalign_01\": 8,\n",
    "    \"Misalign_03\": 9,\n",
    "    \"Misalign_05\": 10,\n",
    "    \"Unbalance_0583mg\": 11,\n",
    "    \"Unbalance_1169mg\": 12,\n",
    "    \"Unbalance_1751mg\": 13,\n",
    "    \"Unbalance_2239mg\": 14,\n",
    "    \"Unbalance_3318mg\": 15,\n",
    "}\n",
    "\n",
    "# ========================\n",
    "# ç”Ÿæˆæ˜ å°„è¡¨\n",
    "# ========================\n",
    "records = []\n",
    "for f in csv_files:\n",
    "    matched_label = None\n",
    "    for key, label in mapping_rules.items():\n",
    "        if key in f:\n",
    "            matched_label = label\n",
    "            break\n",
    "    if matched_label is None:\n",
    "        matched_label = -1\n",
    "    records.append({\n",
    "        \"filename\": f,\n",
    "        \"label\": matched_label\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "df.to_csv(save_path, index=False)\n",
    "\n",
    "print(f\"âœ… å·²ç”Ÿæˆæ˜ å°„è¡¨ï¼š{save_path}\")\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cade51",
   "metadata": {},
   "source": [
    "# æ•°æ®æ··åˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befbc6c3",
   "metadata": {},
   "source": [
    "## å…¨ç±»åˆ«æ··åˆï¼Œç”¨äºåŸºæœ¬æ¨¡å‹è®­ç»ƒè¯„ä¼°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9db9b2c",
   "metadata": {},
   "source": [
    "### mixed data->csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a81ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ===================== 1ï¸âƒ£ å‚æ•°è®¾ç½® =====================\n",
    "raw_dir = \"/home/charles/HZU/Data_processed/my_CIL_V1/KAIST/raw_csv\"\n",
    "mapping_path = \"/home/charles/HZU/Data_processed/my_CIL_V1/KAIST/mapping_table/KAIST_vibration_mapping.csv\"\n",
    "save_path = \"/home/charles/HZU/Data_processed/my_CIL_V1/KAIST/mixed_allclass/mixed_allclass.csv\"\n",
    "used_index_path = \"/home/charles/HZU/Data_processed/my_CIL_V1/KAIST/mixed_allclass/used_indices.csv\"\n",
    "\n",
    "# ===================== 2ï¸âƒ£ è¯»å–æ˜ å°„è¡¨ =====================\n",
    "mapping = pd.read_csv(mapping_path)\n",
    "print(f\"âœ… æ˜ å°„è¡¨è¯»å–æˆåŠŸï¼Œå…± {len(mapping)} æ¡\")\n",
    "\n",
    "# ===================== 3ï¸âƒ£ æ¯ç±»çœŸå®æŠ½å–æ•°é‡ =====================\n",
    "sample_dict = { 1: 2000, # normal \n",
    "                2: 1000, \n",
    "                3: 800,\n",
    "                4: 900, \n",
    "                \n",
    "                1: 1000,\n",
    "                5: 500, \n",
    "                6: 1500, \n",
    "                7: 800,\n",
    "\n",
    "                1: 2000, \n",
    "                8: 900, \n",
    "                9: 1500,\n",
    "\n",
    "                1: 1600, \n",
    "                10: 800, \n",
    "                11: 900, \n",
    "                12: 600, \n",
    "                \n",
    "                1: 800, \n",
    "                13: 600, \n",
    "                14: 900, \n",
    "                }\n",
    "\n",
    "# ===================== 4ï¸âƒ£ å·²ç”¨ç´¢å¼•åŠ è½½ =====================\n",
    "if os.path.exists(used_index_path):\n",
    "    used_indices = pd.read_csv(used_index_path)\n",
    "else:\n",
    "    used_indices = pd.DataFrame(columns=[\"source_file\", \"index\"])\n",
    "\n",
    "# ===================== 5ï¸âƒ£ åˆ›å»ºè¾“å‡ºæ–‡ä»¶ï¼ˆç¬¬ä¸€æ¬¡å†™å…¥æ—¶åŠ è¡¨å¤´ï¼‰ =====================\n",
    "first_write = True\n",
    "if os.path.exists(save_path):\n",
    "    os.remove(save_path)  # é¿å…æ—§æ–‡ä»¶å¹²æ‰°\n",
    "    print(\"âš™ï¸ å·²æ¸…ç©ºæ—§çš„æ··åˆæ–‡ä»¶ã€‚\")\n",
    "\n",
    "# ===================== 6ï¸âƒ£ åˆ†æ‰¹æŠ½æ ·é€»è¾‘ =====================\n",
    "for fname in os.listdir(raw_dir):\n",
    "    if not fname.endswith(\".csv\"): \n",
    "        continue\n",
    "    if \"2Nm\" in fname:  # ğŸš« æ’é™¤2Nm\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(raw_dir, fname)\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # ä»æ˜ å°„è¡¨ä¸­è·å–ç±»åˆ«\n",
    "    label = mapping.loc[mapping[\"filename\"] == fname, \"label\"].values[0]\n",
    "    df[\"label\"] = label\n",
    "    df[\"source_file\"] = fname\n",
    "\n",
    "    # æŸ¥å‡ºè¿™ä¸ª label éœ€è¦æŠ½å–å¤šå°‘æ ·æœ¬\n",
    "    if label not in sample_dict:\n",
    "        print(f\"âš ï¸ {fname} (label={label}) æœªåœ¨ sample_dict ä¸­ï¼Œè·³è¿‡ã€‚\")\n",
    "        continue\n",
    "    need_n = sample_dict[label]\n",
    "    \n",
    "    # ä»å½“å‰æ–‡ä»¶ä¸­è¿‡æ»¤æ‰å·²ä½¿ç”¨è¿‡çš„æ•°æ®\n",
    "    used_idx = used_indices.loc[used_indices[\"source_file\"] == fname, \"index\"].tolist()\n",
    "    df_avail = df.loc[~df.index.isin(used_idx)]\n",
    "\n",
    "    # å¦‚æœå½“å‰ç±»åˆ«çš„æ•°æ®å·²ç»å¤Ÿäº†ï¼Œè·³è¿‡\n",
    "    already_have = used_indices[\"source_file\"].isin(mapping.loc[mapping[\"label\"] == label, \"filename\"]).sum()\n",
    "    if already_have >= need_n:\n",
    "        print(f\"âœ… ç±»åˆ« {label} å·²æŠ½å–è¶³å¤Ÿæ ·æœ¬ ({already_have} >= {need_n})ï¼Œè·³è¿‡ {fname}\")\n",
    "        continue\n",
    "\n",
    "    # å½“å‰è¿˜éœ€çš„æ•°é‡\n",
    "    remain = need_n - already_have\n",
    "    if remain <= 0:\n",
    "        continue\n",
    "\n",
    "    # å½“å‰æ–‡ä»¶å¯ç”¨æ•°é‡\n",
    "    take_n = min(remain, len(df_avail))\n",
    "    if take_n == 0:\n",
    "        continue\n",
    "\n",
    "    sampled_df = df_avail.sample(n=take_n, random_state=42)\n",
    "    \n",
    "    # å†™å…¥ç»“æœæ–‡ä»¶ï¼ˆè¿½åŠ æ¨¡å¼ï¼‰\n",
    "    sampled_df.to_csv(save_path, mode=\"a\", header=first_write, index=False)\n",
    "    first_write = False\n",
    "\n",
    "    # æ›´æ–° used_indices\n",
    "    new_used = pd.DataFrame({\n",
    "        \"source_file\": fname,\n",
    "        \"index\": sampled_df.index\n",
    "    })\n",
    "    used_indices = pd.concat([used_indices, new_used], ignore_index=True)\n",
    "\n",
    "    print(f\"ğŸ“¦ å·²ä» {fname} (label={label}) æŠ½å– {take_n} æ¡ï¼Œå‰©ä½™ {remain - take_n} æ¡å¾…è¡¥ã€‚\")\n",
    "\n",
    "# ===================== 7ï¸âƒ£ ä¿å­˜ä½¿ç”¨è®°å½• =====================\n",
    "used_indices.to_csv(used_index_path, index=False)\n",
    "print(f\"âœ… æ··åˆæ•°æ®é€æ­¥ä¿å­˜å®Œæˆï¼š{save_path}\")\n",
    "print(f\"ğŸ“ å·²æ›´æ–°ä½¿ç”¨è®°å½•ï¼š{used_index_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f801c064",
   "metadata": {},
   "source": [
    "### mixed_data->pyg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47219ccb",
   "metadata": {},
   "source": [
    "#### æ—¶é—´é‚»ç‚¹å»ºå›¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8b4744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·²æ·»åŠ è·¯å¾„ï¼š/home/charles/HZU/Industrial_Software_Testing/Industrial_Software_Testing/my_CIL_V1/data_process/KAIST\n",
      "âœ… å·²æ·»åŠ  my_libï¼š/home/charles/HZU/Industrial_Software_Testing/Industrial_Software_Testing/my_CIL_V1/data_process/KAIST/my_lib\n",
      "ğŸ“Š åŸå§‹æ•°æ®å½¢çŠ¶: (12500, 7)\n",
      "ğŸ§¹ å·²ç§»é™¤æœ€åä¸€åˆ—åå½¢çŠ¶: (12500, 6)\n",
      "âœ… å·²ç”Ÿæˆå»é™¤æ ‡ç­¾åˆ—çš„ä¸´æ—¶æ–‡ä»¶: /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/mixed_allclass/mixed_allclass_nofinal.csv\n",
      "âœ… å›¾ç»“æ„æ„å»ºå®Œæˆï¼Œå…± 12500 ä¸ªèŠ‚ç‚¹ï¼Œ125000 æ¡æ— å‘è¾¹\n",
      "ğŸ“ nodes.csv: /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/mixed_allclass/pyg_data/time/nodes.csv\n",
      "ğŸ“ edges.csv: /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/mixed_allclass/pyg_data/time/edges.csv\n",
      "ğŸ“ graph.pt : /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/mixed_allclass/pyg_data/time/graph.pt\n",
      "ğŸ§© ç‰¹å¾ç»´åº¦: 4 (å·²è‡ªåŠ¨å¿½ç•¥é¦–åˆ—ä¸æ ‡ç­¾åˆ—)\n",
      "\n",
      "âœ… å±€éƒ¨æ—¶åºå›¾å·²æ„å»ºå®Œæˆï¼š\n",
      "ğŸ“ èŠ‚ç‚¹æ–‡ä»¶: /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/mixed_allclass/pyg_data/time/nodes.csv\n",
      "ğŸ“ è¾¹æ–‡ä»¶:   /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/mixed_allclass/pyg_data/time/edges.csv\n",
      "ğŸ“ å›¾æ–‡ä»¶:   /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/mixed_allclass/pyg_data/time/graph.pt\n"
     ]
    }
   ],
   "source": [
    "# ================== 1ï¸âƒ£ å¯¼å…¥è·¯å¾„ä¸å‡½æ•° ==================\n",
    "%run ../_init_path.py\n",
    "from build_pyg_data import build_local_temporal_graph\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ================== 2ï¸âƒ£ å‚æ•°è®¾ç½® ==================\n",
    "csv_path = \"/home/charles/HZU/Data_processed/my_CIL_V1/KAIST/mixed_allclass/mixed_allclass.csv\"\n",
    "save_dir = \"/home/charles/HZU/Data_processed/my_CIL_V1/KAIST/mixed_allclass/pyg_data/time\"\n",
    "num_edges = 10  # æ¯ä¸ªèŠ‚ç‚¹çš„è¾¹æ•°ï¼ˆä¸Šä¸‹å¹³å‡åˆ†é…ï¼‰\n",
    "\n",
    "# ================== 3ï¸âƒ£ é¢„å¤„ç†ï¼šå¿½ç•¥æœ€åä¸€åˆ— ==================\n",
    "if not os.path.exists(csv_path):\n",
    "    raise FileNotFoundError(f\"âŒ æ‰¾ä¸åˆ°æ··åˆæ–‡ä»¶: {csv_path}\")\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "print(f\"ğŸ“Š åŸå§‹æ•°æ®å½¢çŠ¶: {df.shape}\")\n",
    "\n",
    "# å»æ‰æœ€åä¸€åˆ—ï¼ˆé€šå¸¸ä¸ºæ ‡ç­¾ï¼‰\n",
    "df = df.iloc[:, :-1]\n",
    "print(f\"ğŸ§¹ å·²ç§»é™¤æœ€åä¸€åˆ—åå½¢çŠ¶: {df.shape}\")\n",
    "\n",
    "# ä¿å­˜ä¸´æ—¶æ–‡ä»¶ä¾›å»ºå›¾ä½¿ç”¨\n",
    "temp_csv_path = csv_path.replace(\".csv\", \"_nofinal.csv\")\n",
    "df.to_csv(temp_csv_path, index=False)\n",
    "print(f\"âœ… å·²ç”Ÿæˆå»é™¤æ ‡ç­¾åˆ—çš„ä¸´æ—¶æ–‡ä»¶: {temp_csv_path}\")\n",
    "\n",
    "# ================== 4ï¸âƒ£ è°ƒç”¨å‡½æ•°å»ºå›¾ ==================\n",
    "nodes_csv, edges_csv, graph_pt = build_local_temporal_graph(\n",
    "    csv_path=temp_csv_path,\n",
    "    save_dir=save_dir,\n",
    "    num_edges=num_edges\n",
    ")\n",
    "\n",
    "# ================== 5ï¸âƒ£ è¾“å‡ºç»“æœè·¯å¾„ ==================\n",
    "print(\"\\nâœ… å±€éƒ¨æ—¶åºå›¾å·²æ„å»ºå®Œæˆï¼š\")\n",
    "print(f\"ğŸ“ èŠ‚ç‚¹æ–‡ä»¶: {nodes_csv}\")\n",
    "print(f\"ğŸ“ è¾¹æ–‡ä»¶:   {edges_csv}\")\n",
    "print(f\"ğŸ“ å›¾æ–‡ä»¶:   {graph_pt}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42c5a41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·²æ·»åŠ è·¯å¾„ï¼š/home/charles/HZU/Industrial_Software_Testing/Industrial_Software_Testing/my_CIL_V1/data_process/KAIST\n",
      "âœ… å·²æ·»åŠ  my_libï¼š/home/charles/HZU/Industrial_Software_Testing/Industrial_Software_Testing/my_CIL_V1/data_process/KAIST/my_lib\n",
      "ğŸš€ å¼€å§‹ä¸ºå›¾æ·»åŠ æ©ç  ...\n",
      "ğŸ“¦ å·²åŠ è½½å›¾æ–‡ä»¶ï¼Œå…± 12500 ä¸ªèŠ‚ç‚¹ã€‚\n",
      "âœ… å·²ç”Ÿæˆä¸»æ©ç ï¼štrain=7500, val=2500, test=2500\n",
      "ğŸ¯ è®­ç»ƒé›†å†…éƒ¨åˆ’åˆ†ï¼šwith_label=3000, no_label=4500\n",
      "ğŸ’¾ å·²å°†å«æ©ç çš„æ–°å›¾æ–‡ä»¶ä¿å­˜è‡³ï¼š/home/charles/HZU/Data_processed/my_CIL_V1/KAIST/mixed_allclass/pyg_data/time/mixed_allclass_arabic_graph_withmask.pt\n",
      "\n",
      "âœ… æ©ç ç”Ÿæˆä¸ä¿å­˜å®Œæˆã€‚\n",
      "\n",
      "ğŸ§© éªŒè¯ç”Ÿæˆçš„å›¾ç»“æ„ä¸æ©ç  ...\n",
      "\n",
      "ğŸ“¦ å›¾æ•°æ®ç»“æ„: Data(x=[12500, 4], edge_index=[2, 250000], y=[12500], train_mask=[12500], val_mask=[12500], test_mask=[12500], train_withlabel_mask=[12500], train_nolabel_mask=[12500])\n",
      "x shape: torch.Size([12500, 4]), y shape: torch.Size([12500])\n",
      "å‰5ä¸ªæ ‡ç­¾: [1, 1, 1, 1, 1]\n",
      "train_mask               : âœ… å­˜åœ¨\n",
      "val_mask                 : âœ… å­˜åœ¨\n",
      "test_mask                : âœ… å­˜åœ¨\n",
      "train_withlabel_mask     : âœ… å­˜åœ¨\n",
      "train_nolabel_mask       : âœ… å­˜åœ¨\n",
      "\n",
      "ğŸ“Š æ©ç æ•°é‡éªŒè¯ï¼š\n",
      "  train_mask         = 7500\n",
      "  val_mask           = 2500\n",
      "  test_mask          = 2500\n",
      "  â””â”€ train_withlabel = 3000\n",
      "  â””â”€ train_nolabel   = 4500\n",
      "  åˆè®¡èŠ‚ç‚¹æ•°         = 12500\n",
      "âœ… æ©ç åˆ’åˆ†æ€»æ•°åŒ¹é…èŠ‚ç‚¹æ€»æ•°\n",
      "\n",
      "ğŸ¯ æ©ç éªŒè¯å®Œæˆã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/HZU/Industrial_Software_Testing/Industrial_Software_Testing/my_CIL_V1/data_process/KAIST/my_lib/build_pyg_data.py:278: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(graph_path)\n",
      "/tmp/ipykernel_3013146/1308106676.py:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(new_graph_path)\n"
     ]
    }
   ],
   "source": [
    "# ================== 1ï¸âƒ£ å¯¼å…¥è·¯å¾„ä¸å‡½æ•° ==================\n",
    "%run ../_init_path.py\n",
    "from build_pyg_data import add_random_masks_with_label_split\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# ================== 2ï¸âƒ£ å‚æ•°è®¾ç½® ==================\n",
    "ratios = {\"train\": 0.6, \"val\": 0.2, \"test\": 0.2}\n",
    "\n",
    "graph_path = \"/home/charles/HZU/Data_processed/my_CIL_V1/KAIST/mixed_allclass/pyg_data/time/graph.pt\"\n",
    "save_path = \"/home/charles/HZU/Data_processed/my_CIL_V1/KAIST/mixed_allclass/pyg_data/time/mixed_allclass_arabic_graph_withmask.pt\"\n",
    "\n",
    "# ================== 3ï¸âƒ£ è°ƒç”¨å‡½æ•°ç”Ÿæˆæ©ç  ==================\n",
    "print(\"ğŸš€ å¼€å§‹ä¸ºå›¾æ·»åŠ æ©ç  ...\")\n",
    "new_graph_path = add_random_masks_with_label_split(\n",
    "    graph_path=graph_path,\n",
    "    save_path=save_path,      # è‹¥æƒ³è¦†ç›–æºæ–‡ä»¶åˆ™ç›´æ¥ä¼  None\n",
    "    ratios=ratios,\n",
    "    train_label_ratio=0.4,    # è®­ç»ƒé›†ä¸­40%ä¸ºæœ‰æ ‡ç­¾\n",
    ")\n",
    "print(\"\\nâœ… æ©ç ç”Ÿæˆä¸ä¿å­˜å®Œæˆã€‚\")\n",
    "\n",
    "# ================== 4ï¸âƒ£ åŠ è½½éªŒè¯ ==================\n",
    "print(\"\\nğŸ§© éªŒè¯ç”Ÿæˆçš„å›¾ç»“æ„ä¸æ©ç  ...\")\n",
    "data = torch.load(new_graph_path)\n",
    "\n",
    "# === åŸºæœ¬ç»“æ„ ===\n",
    "print(f\"\\nğŸ“¦ å›¾æ•°æ®ç»“æ„: {data}\")\n",
    "print(f\"x shape: {data.x.shape}, y shape: {data.y.shape}\")\n",
    "print(f\"å‰5ä¸ªæ ‡ç­¾: {data.y[:5].tolist()}\")\n",
    "\n",
    "# === æ©ç å­˜åœ¨æ€§æ£€æŸ¥ ===\n",
    "mask_attrs = [\"train_mask\", \"val_mask\", \"test_mask\", \"train_withlabel_mask\", \"train_nolabel_mask\"]\n",
    "for attr in mask_attrs:\n",
    "    exists = hasattr(data, attr)\n",
    "    print(f\"{attr:<25}: {'âœ… å­˜åœ¨' if exists else 'âŒ ä¸å­˜åœ¨'}\")\n",
    "\n",
    "# === æ©ç åˆ†å¸ƒéªŒè¯ ===\n",
    "if hasattr(data, \"train_mask\"):\n",
    "    total_nodes = data.x.size(0)\n",
    "    n_train = int(data.train_mask.sum())\n",
    "    n_val = int(data.val_mask.sum()) if hasattr(data, \"val_mask\") else 0\n",
    "    n_test = int(data.test_mask.sum()) if hasattr(data, \"test_mask\") else 0\n",
    "    n_withlabel = int(data.train_withlabel_mask.sum()) if hasattr(data, \"train_withlabel_mask\") else 0\n",
    "    n_nolabel = int(data.train_nolabel_mask.sum()) if hasattr(data, \"train_nolabel_mask\") else 0\n",
    "\n",
    "    print(\"\\nğŸ“Š æ©ç æ•°é‡éªŒè¯ï¼š\")\n",
    "    print(f\"  train_mask         = {n_train}\")\n",
    "    print(f\"  val_mask           = {n_val}\")\n",
    "    print(f\"  test_mask          = {n_test}\")\n",
    "    print(f\"  â””â”€ train_withlabel = {n_withlabel}\")\n",
    "    print(f\"  â””â”€ train_nolabel   = {n_nolabel}\")\n",
    "    print(f\"  åˆè®¡èŠ‚ç‚¹æ•°         = {total_nodes}\")\n",
    "    if n_train + n_val + n_test == total_nodes:\n",
    "        print(\"âœ… æ©ç åˆ’åˆ†æ€»æ•°åŒ¹é…èŠ‚ç‚¹æ€»æ•°\")\n",
    "    else:\n",
    "        print(\"âš ï¸ æ³¨æ„ï¼šæ©ç åˆ’åˆ†èŠ‚ç‚¹æ•°ä¸æ€»æ•°ä¸å®Œå…¨åŒ¹é…ï¼Œå¯èƒ½å­˜åœ¨èˆå…¥è¯¯å·®ã€‚\")\n",
    "\n",
    "print(\"\\nğŸ¯ æ©ç éªŒè¯å®Œæˆã€‚\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86614f61",
   "metadata": {},
   "source": [
    "#### ä½™å¼¦ç›¸ä¼¼åº¦å»ºå›¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6545eec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·²æ·»åŠ è·¯å¾„ï¼š/home/charles/HZU/Industrial_Software_Testing/Industrial_Software_Testing/my_CIL_V1/data_process/KAIST\n",
      "âœ… å·²æ·»åŠ  my_libï¼š/home/charles/HZU/Industrial_Software_Testing/Industrial_Software_Testing/my_CIL_V1/data_process/KAIST/my_lib\n",
      "ğŸš€ å¼€å§‹æ„å»ºåŸºäºä½™å¼¦ç›¸ä¼¼åº¦çš„KNNå›¾ ...\n",
      "ğŸ“Š å·²è¯»å–æ•°æ®: (12500, 6)\n",
      "ğŸ§© ä½¿ç”¨ç‰¹å¾åˆ—æ•°: 4 | ç‰¹å¾åˆ—ç¤ºä¾‹: ['vibration_ch1', 'vibration_ch2', 'vibration_ch3', 'vibration_ch4'] ...\n",
      "âš™ï¸ æ­£åœ¨è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦çŸ©é˜µ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” æ­£åœ¨ä¸ºæ¯ä¸ªèŠ‚ç‚¹é€‰å– 10 ä¸ªæœ€ç›¸ä¼¼é‚»å±…...\n",
      "âœ… å›¾æ„å»ºå®Œæˆï¼Œå…± 12500 ä¸ªèŠ‚ç‚¹ï¼Œ125000 æ¡æ— å‘è¾¹ã€‚\n",
      "ğŸ“ èŠ‚ç‚¹æ–‡ä»¶: /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/mixed_allclass/pyg_data/cos_knn/mixed_allclass_nofinal_nodes.csv\n",
      "ğŸ“ è¾¹æ–‡ä»¶:   /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/mixed_allclass/pyg_data/cos_knn/mixed_allclass_nofinal_edges.csv\n",
      "ğŸ“ å›¾æ–‡ä»¶:   /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/mixed_allclass/pyg_data/cos_knn/mixed_allclass_nofinal_graph.pt\n",
      "\n",
      "âœ… å›¾ç»“æ„å·²ç”Ÿæˆï¼š\n",
      "ğŸ“ èŠ‚ç‚¹æ–‡ä»¶: /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/mixed_allclass/pyg_data/cos_knn/mixed_allclass_nofinal_nodes.csv\n",
      "ğŸ“ è¾¹æ–‡ä»¶:   /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/mixed_allclass/pyg_data/cos_knn/mixed_allclass_nofinal_edges.csv\n",
      "ğŸ“ å›¾æ–‡ä»¶:   /home/charles/HZU/Data_processed/my_CIL_V1/KAIST/mixed_allclass/pyg_data/cos_knn/mixed_allclass_nofinal_graph.pt\n",
      "\n",
      "ğŸ§© éªŒè¯ç”Ÿæˆçš„ PyG å›¾æ•°æ®ç»“æ„ ...\n",
      "ğŸ“¦ Data å¯¹è±¡ç»“æ„: Data(x=[12500, 4], edge_index=[2, 250000], y=[12500])\n",
      "ğŸ§® èŠ‚ç‚¹æ•°: 12500\n",
      "ğŸ§® è¾¹æ•°: 125000ï¼ˆæ— å‘è¾¹ï¼‰\n",
      "ğŸ§© ç‰¹å¾ç»´åº¦: 4\n",
      "ğŸ·ï¸  æ ‡ç­¾å­˜åœ¨: âœ… æ˜¯\n",
      "ğŸ¯ æ ‡ç­¾ç±»åˆ«æ•°é‡: 14 | ç±»åˆ«: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10)]\n",
      "å‰5ä¸ªæ ‡ç­¾: [1 1 1 1 1]\n",
      "\n",
      "ğŸ“Š éªŒè¯èŠ‚ç‚¹å’Œè¾¹ CSV æ–‡ä»¶ ...\n",
      "âœ… èŠ‚ç‚¹æ–‡ä»¶è¡Œæ•°: 12500 | ä¸å›¾èŠ‚ç‚¹æ•° ä¸€è‡´ âœ…\n",
      "âœ… è¾¹æ–‡ä»¶è¡Œæ•°: 250000 | æ¯ä¸¤è¡Œå¯¹åº”ä¸€æ¡æ— å‘è¾¹\n",
      "ğŸ§® è¾¹ä¸­æ¶‰åŠçš„å”¯ä¸€èŠ‚ç‚¹æ•°: 12500\n",
      "\n",
      "ğŸ¯ å›¾æ•°æ®éªŒè¯å®Œæˆã€‚\n"
     ]
    }
   ],
   "source": [
    "# ================== 1ï¸âƒ£ å¯¼å…¥è·¯å¾„ä¸å‡½æ•° ==================\n",
    "%run ../_init_path.py\n",
    "from build_pyg_data import build_similarity_knn_graph\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# ================== 2ï¸âƒ£ å‚æ•°è®¾ç½® ==================\n",
    "csv_path = \"/home/charles/HZU/Data_processed/my_CIL_V1/KAIST/mixed_allclass/mixed_allclass_nofinal.csv\"\n",
    "save_dir = \"/home/charles/HZU/Data_processed/my_CIL_V1/KAIST/mixed_allclass/pyg_data/cos_knn\"\n",
    "\n",
    "# ================== 3ï¸âƒ£ è°ƒç”¨å»ºå›¾å‡½æ•° ==================\n",
    "print(\"ğŸš€ å¼€å§‹æ„å»ºåŸºäºä½™å¼¦ç›¸ä¼¼åº¦çš„KNNå›¾ ...\")\n",
    "nodes_csv, edges_csv, graph_pt = build_similarity_knn_graph(\n",
    "    csv_path=csv_path,\n",
    "    save_dir=save_dir,\n",
    "    num_edges=10\n",
    ")\n",
    "print(\"\\nâœ… å›¾ç»“æ„å·²ç”Ÿæˆï¼š\")\n",
    "print(f\"ğŸ“ èŠ‚ç‚¹æ–‡ä»¶: {nodes_csv}\")\n",
    "print(f\"ğŸ“ è¾¹æ–‡ä»¶:   {edges_csv}\")\n",
    "print(f\"ğŸ“ å›¾æ–‡ä»¶:   {graph_pt}\")\n",
    "\n",
    "# ================== 4ï¸âƒ£ éªŒè¯ç”Ÿæˆçš„å›¾æ•°æ® ==================\n",
    "print(\"\\nğŸ§© éªŒè¯ç”Ÿæˆçš„ PyG å›¾æ•°æ®ç»“æ„ ...\")\n",
    "\n",
    "# è¯»å– PyG å¯¹è±¡\n",
    "data = torch.load(graph_pt, weights_only=False)\n",
    "\n",
    "# === åŸºç¡€ä¿¡æ¯ ===\n",
    "num_nodes = data.x.size(0)\n",
    "num_edges = data.edge_index.size(1)\n",
    "num_features = data.x.size(1)\n",
    "has_label = hasattr(data, \"y\") and data.y is not None\n",
    "\n",
    "print(f\"ğŸ“¦ Data å¯¹è±¡ç»“æ„: {data}\")\n",
    "print(f\"ğŸ§® èŠ‚ç‚¹æ•°: {num_nodes}\")\n",
    "print(f\"ğŸ§® è¾¹æ•°: {num_edges // 2}ï¼ˆæ— å‘è¾¹ï¼‰\")\n",
    "print(f\"ğŸ§© ç‰¹å¾ç»´åº¦: {num_features}\")\n",
    "print(f\"ğŸ·ï¸  æ ‡ç­¾å­˜åœ¨: {'âœ… æ˜¯' if has_label else 'âŒ å¦'}\")\n",
    "\n",
    "# === æ ‡ç­¾éªŒè¯ ===\n",
    "if has_label:\n",
    "    y = data.y.cpu().numpy()\n",
    "    unique_labels = sorted(set(y))\n",
    "    print(f\"ğŸ¯ æ ‡ç­¾ç±»åˆ«æ•°é‡: {len(unique_labels)} | ç±»åˆ«: {unique_labels[:10]}\")\n",
    "    print(f\"å‰5ä¸ªæ ‡ç­¾: {y[:5]}\")\n",
    "else:\n",
    "    print(\"âš ï¸ æœªæ£€æµ‹åˆ° data.yï¼Œæ ‡ç­¾åˆ—å¯èƒ½ç¼ºå¤±æˆ–æœªæ­£ç¡®æŒ‡å®šã€‚\")\n",
    "\n",
    "# === èŠ‚ç‚¹/è¾¹æ–‡ä»¶éªŒè¯ ===\n",
    "print(\"\\nğŸ“Š éªŒè¯èŠ‚ç‚¹å’Œè¾¹ CSV æ–‡ä»¶ ...\")\n",
    "df_nodes = pd.read_csv(nodes_csv)\n",
    "df_edges = pd.read_csv(edges_csv)\n",
    "\n",
    "print(f\"âœ… èŠ‚ç‚¹æ–‡ä»¶è¡Œæ•°: {len(df_nodes)} | ä¸å›¾èŠ‚ç‚¹æ•° {'ä¸€è‡´ âœ…' if len(df_nodes)==num_nodes else 'ä¸ä¸€è‡´ âš ï¸'}\")\n",
    "print(f\"âœ… è¾¹æ–‡ä»¶è¡Œæ•°: {len(df_edges)} | æ¯ä¸¤è¡Œå¯¹åº”ä¸€æ¡æ— å‘è¾¹\")\n",
    "\n",
    "if \"source\" in df_edges.columns and \"target\" in df_edges.columns:\n",
    "    unique_nodes = pd.concat([df_edges[\"source\"], df_edges[\"target\"]]).nunique()\n",
    "    print(f\"ğŸ§® è¾¹ä¸­æ¶‰åŠçš„å”¯ä¸€èŠ‚ç‚¹æ•°: {unique_nodes}\")\n",
    "else:\n",
    "    print(\"âš ï¸ è¾¹æ–‡ä»¶ç¼ºå°‘ 'source' æˆ– 'target' åˆ—ï¼\")\n",
    "\n",
    "print(\"\\nğŸ¯ å›¾æ•°æ®éªŒè¯å®Œæˆã€‚\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d14fb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·²æ·»åŠ è·¯å¾„ï¼š/home/charles/HZU/Industrial_Software_Testing/Industrial_Software_Testing/my_CIL_V1/data_process/KAIST\n",
      "âœ… å·²æ·»åŠ  my_libï¼š/home/charles/HZU/Industrial_Software_Testing/Industrial_Software_Testing/my_CIL_V1/data_process/KAIST/my_lib\n",
      "ğŸš€ å¼€å§‹ä¸ºå›¾æ·»åŠ éšæœºæ©ç  ...\n",
      "ğŸ“¦ å·²åŠ è½½å›¾æ–‡ä»¶ï¼Œå…± 12500 ä¸ªèŠ‚ç‚¹ã€‚\n",
      "âœ… å·²ç”Ÿæˆä¸»æ©ç ï¼štrain=7500, val=2500, test=2500\n",
      "ğŸ¯ è®­ç»ƒé›†å†…éƒ¨åˆ’åˆ†ï¼šwith_label=3000, no_label=4500\n",
      "ğŸ’¾ å·²å°†å«æ©ç çš„æ–°å›¾æ–‡ä»¶ä¿å­˜è‡³ï¼š/home/charles/HZU/Data_processed/my_CIL_V1/KAIST/mixed_allclass/pyg_data/cos_knn/mixed_allclass_arabic_graph_withmask.pt\n",
      "\n",
      "âœ… æ©ç ç”Ÿæˆä¸ä¿å­˜å®Œæˆï¼š/home/charles/HZU/Data_processed/my_CIL_V1/KAIST/mixed_allclass/pyg_data/cos_knn/mixed_allclass_arabic_graph_withmask.pt\n",
      "\n",
      "ğŸ§© éªŒè¯ç”Ÿæˆçš„å›¾ç»“æ„ä¸æ©ç  ...\n",
      "\n",
      "ğŸ“¦ å›¾æ•°æ®ç»“æ„: Data(x=[12500, 4], edge_index=[2, 250000], y=[12500], train_mask=[12500], val_mask=[12500], test_mask=[12500], train_withlabel_mask=[12500], train_nolabel_mask=[12500])\n",
      "x shape: torch.Size([12500, 4]), y shape: torch.Size([12500])\n",
      "å‰5ä¸ªæ ‡ç­¾: [1, 1, 1, 1, 1]\n",
      "\n",
      "ğŸ“‹ æ©ç å­˜åœ¨æ€§æ£€æŸ¥ï¼š\n",
      "  train_mask               : âœ… å­˜åœ¨\n",
      "  val_mask                 : âœ… å­˜åœ¨\n",
      "  test_mask                : âœ… å­˜åœ¨\n",
      "  train_withlabel_mask     : âœ… å­˜åœ¨\n",
      "  train_nolabel_mask       : âœ… å­˜åœ¨\n",
      "\n",
      "ğŸ“Š æ©ç æ•°é‡éªŒè¯ï¼š\n",
      "  train_mask         = 7500\n",
      "  val_mask           = 2500\n",
      "  test_mask          = 2500\n",
      "  â””â”€ train_withlabel = 3000\n",
      "  â””â”€ train_nolabel   = 4500\n",
      "  åˆè®¡èŠ‚ç‚¹æ•°         = 12500\n",
      "âœ… æ©ç åˆ’åˆ†æ€»æ•°åŒ¹é…èŠ‚ç‚¹æ€»æ•°\n",
      "\n",
      "ğŸ¯ æ ‡ç­¾åˆ†å¸ƒæ£€æŸ¥ï¼š\n",
      "  æ ‡ç­¾ç±»åˆ«æ•°: 14\n",
      "  ç±»åˆ«ç¤ºä¾‹: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "\n",
      "ğŸ¯ æ©ç ä¸æ ‡ç­¾éªŒè¯å®Œæˆã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/HZU/Industrial_Software_Testing/Industrial_Software_Testing/my_CIL_V1/data_process/KAIST/my_lib/build_pyg_data.py:278: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(graph_path)\n"
     ]
    }
   ],
   "source": [
    "# ================== 1ï¸âƒ£ å¯¼å…¥è·¯å¾„ä¸å‡½æ•° ==================\n",
    "%run ../_init_path.py\n",
    "from build_pyg_data import add_random_masks_with_label_split\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# ================== 2ï¸âƒ£ å‚æ•°è®¾ç½® ==================\n",
    "ratios = {\"train\": 0.6, \"val\": 0.2, \"test\": 0.2}\n",
    "\n",
    "graph_path = \"/home/charles/HZU/Data_processed/my_CIL_V1/KAIST/mixed_allclass/pyg_data/cos_knn/mixed_allclass_nofinal_graph.pt\"\n",
    "save_path  = \"/home/charles/HZU/Data_processed/my_CIL_V1/KAIST/mixed_allclass/pyg_data/cos_knn/mixed_allclass_arabic_graph_withmask.pt\"\n",
    "\n",
    "# ================== 3ï¸âƒ£ ç”Ÿæˆæ©ç  ==================\n",
    "print(\"ğŸš€ å¼€å§‹ä¸ºå›¾æ·»åŠ éšæœºæ©ç  ...\")\n",
    "new_graph_path = add_random_masks_with_label_split(\n",
    "    graph_path=graph_path,\n",
    "    save_path=save_path,     # è‹¥æƒ³è¦†ç›–æºæ–‡ä»¶åˆ™ç›´æ¥ä¼  None\n",
    "    ratios=ratios,\n",
    "    train_label_ratio=0.4,   # è®­ç»ƒé›†ä¸­40%ä¸ºæœ‰æ ‡ç­¾\n",
    ")\n",
    "print(f\"\\nâœ… æ©ç ç”Ÿæˆä¸ä¿å­˜å®Œæˆï¼š{new_graph_path}\")\n",
    "\n",
    "# ================== 4ï¸âƒ£ éªŒè¯ç”Ÿæˆç»“æœ ==================\n",
    "print(\"\\nğŸ§© éªŒè¯ç”Ÿæˆçš„å›¾ç»“æ„ä¸æ©ç  ...\")\n",
    "\n",
    "# è¯»å– PyG æ•°æ®\n",
    "data = torch.load(new_graph_path, weights_only=False)\n",
    "\n",
    "# === åŸºæœ¬ä¿¡æ¯ ===\n",
    "print(f\"\\nğŸ“¦ å›¾æ•°æ®ç»“æ„: {data}\")\n",
    "print(f\"x shape: {data.x.shape}, y shape: {data.y.shape}\")\n",
    "print(f\"å‰5ä¸ªæ ‡ç­¾: {data.y[:5].tolist()}\")\n",
    "\n",
    "# === æ©ç å­˜åœ¨æ€§æ£€æµ‹ ===\n",
    "mask_attrs = [\"train_mask\", \"val_mask\", \"test_mask\", \"train_withlabel_mask\", \"train_nolabel_mask\"]\n",
    "print(\"\\nğŸ“‹ æ©ç å­˜åœ¨æ€§æ£€æŸ¥ï¼š\")\n",
    "for attr in mask_attrs:\n",
    "    print(f\"  {attr:<25}: {'âœ… å­˜åœ¨' if hasattr(data, attr) else 'âŒ ä¸å­˜åœ¨'}\")\n",
    "\n",
    "# === æ©ç ç»Ÿè®¡ ===\n",
    "if hasattr(data, \"train_mask\"):\n",
    "    total_nodes = data.x.size(0)\n",
    "    n_train = int(data.train_mask.sum())\n",
    "    n_val   = int(data.val_mask.sum()) if hasattr(data, \"val_mask\") else 0\n",
    "    n_test  = int(data.test_mask.sum()) if hasattr(data, \"test_mask\") else 0\n",
    "    n_with  = int(data.train_withlabel_mask.sum()) if hasattr(data, \"train_withlabel_mask\") else 0\n",
    "    n_nol   = int(data.train_nolabel_mask.sum()) if hasattr(data, \"train_nolabel_mask\") else 0\n",
    "\n",
    "    print(\"\\nğŸ“Š æ©ç æ•°é‡éªŒè¯ï¼š\")\n",
    "    print(f\"  train_mask         = {n_train}\")\n",
    "    print(f\"  val_mask           = {n_val}\")\n",
    "    print(f\"  test_mask          = {n_test}\")\n",
    "    print(f\"  â””â”€ train_withlabel = {n_with}\")\n",
    "    print(f\"  â””â”€ train_nolabel   = {n_nol}\")\n",
    "    print(f\"  åˆè®¡èŠ‚ç‚¹æ•°         = {total_nodes}\")\n",
    "    if n_train + n_val + n_test == total_nodes:\n",
    "        print(\"âœ… æ©ç åˆ’åˆ†æ€»æ•°åŒ¹é…èŠ‚ç‚¹æ€»æ•°\")\n",
    "    else:\n",
    "        print(\"âš ï¸ æ³¨æ„ï¼šæ©ç åˆ’åˆ†èŠ‚ç‚¹æ•°ä¸æ€»æ•°ä¸å®Œå…¨åŒ¹é…ï¼Œå¯èƒ½å­˜åœ¨èˆå…¥è¯¯å·®ã€‚\")\n",
    "\n",
    "# === æ ‡ç­¾ç»Ÿè®¡ ===\n",
    "unique_labels = sorted(set(data.y.cpu().numpy().tolist()))\n",
    "print(\"\\nğŸ¯ æ ‡ç­¾åˆ†å¸ƒæ£€æŸ¥ï¼š\")\n",
    "print(f\"  æ ‡ç­¾ç±»åˆ«æ•°: {len(unique_labels)}\")\n",
    "print(f\"  ç±»åˆ«ç¤ºä¾‹: {unique_labels[:10]}\")\n",
    "\n",
    "print(\"\\nğŸ¯ æ©ç ä¸æ ‡ç­¾éªŒè¯å®Œæˆã€‚\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817eb662",
   "metadata": {},
   "source": [
    "#### time + cos_knn èåˆå»ºå›¾"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
