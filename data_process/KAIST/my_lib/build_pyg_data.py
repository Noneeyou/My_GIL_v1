import os
import scipy.io as sio
import pandas as pd
import numpy as np
import torch
from torch_geometric.data import Data
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.neighbors import NearestNeighbors

def build_local_temporal_graph(csv_path: str, save_dir: str, num_edges: int = 10):
    """
    åŸºäºæ—¶é—´é¡ºåºæ„å»ºå±€éƒ¨æ—¶åºå›¾ã€‚
    æ¯ä¸€è¡Œæ˜¯ä¸€ä¸ªèŠ‚ç‚¹ï¼Œä¸Šä¸‹ç›¸é‚»æ ·æœ¬æ„æˆè¾¹ã€‚

    å‚æ•°:
        csv_path (str): è¾“å…¥ CSV æ–‡ä»¶è·¯å¾„ã€‚
        save_dir (str): å›¾ç»“æ„æ–‡ä»¶çš„ä¿å­˜æ–‡ä»¶å¤¹ã€‚
        num_edges (int): æ¯ä¸ªèŠ‚ç‚¹çš„è¾¹æ•°ï¼ˆä¸Šä¸‹å¹³å‡åˆ†é…ï¼‰ã€‚
                         ä¾‹å¦‚ 10 è¡¨ç¤ºä¸Š5ä¸‹5ï¼›è‹¥è¾¹ç•Œä¸è¶³åˆ™å•è¾¹è¡¥é½ã€‚
    è¿”å›:
        (nodes_csv, edges_csv, graph_pt): ä¿å­˜çš„æ–‡ä»¶è·¯å¾„å…ƒç»„ã€‚
    """
    os.makedirs(save_dir, exist_ok=True)

    # è¯»å–æ•°æ®
    df = pd.read_csv(csv_path)
    num_nodes = len(df)
    half = num_edges // 2

    # === æ„å»ºè¾¹åˆ—è¡¨ ===
    edges = []
    for i in range(num_nodes):
        # ä¸Šæ–¹èŠ‚ç‚¹ç´¢å¼•
        start_up = max(0, i - half)
        # ä¸‹æ–¹èŠ‚ç‚¹ç´¢å¼•
        end_down = min(num_nodes, i + half + 1)

        up_neighbors = list(range(start_up, i))
        down_neighbors = list(range(i + 1, end_down))

        # è‹¥ä¸¤è¾¹ä¸å¤Ÿæ•°é‡ï¼Œè¡¥å¦ä¸€è¾¹
        total_needed = num_edges
        current = len(up_neighbors) + len(down_neighbors)
        if current < total_needed:
            remaining = total_needed - current
            # ä¼˜å…ˆè¡¥ä¸‹è¾¹
            if i + half + 1 >= num_nodes:  # ä¸‹æ–¹ä¸å¤Ÿ
                extra_up = list(range(max(0, start_up - remaining), start_up))
                up_neighbors = extra_up + up_neighbors
            elif i - half < 0:  # ä¸Šæ–¹ä¸å¤Ÿ
                extra_down = list(range(end_down, min(num_nodes, end_down + remaining)))
                down_neighbors += extra_down

        # æ·»åŠ è¾¹ï¼ˆåŒå‘ï¼‰
        for j in up_neighbors + down_neighbors:
            edges.append((i, j))
            edges.append((j, i))

    # === ä¿å­˜èŠ‚ç‚¹ä¸è¾¹ ===
    nodes_path = os.path.join(save_dir, "nodes.csv")
    edges_path = os.path.join(save_dir, "edges.csv")
    graph_path = os.path.join(save_dir, "graph.pt")

    df.to_csv(nodes_path, index=False)
    edge_df = pd.DataFrame(edges, columns=["source", "target"])
    edge_df.to_csv(edges_path, index=False)

    # === è½¬æ¢ä¸ºPyGå›¾ç»“æ„ ===
    edge_index = torch.tensor(edges, dtype=torch.long).T
    x = torch.tensor(df.values, dtype=torch.float)
    data = Data(x=x, edge_index=edge_index)

    torch.save(data, graph_path)

    print(f"âœ… å›¾ç»“æ„æ„å»ºå®Œæˆï¼Œå…± {num_nodes} ä¸ªèŠ‚ç‚¹ï¼Œ{len(edges)//2} æ¡æ— å‘è¾¹")
    print(f"ğŸ“ nodes.csv: {nodes_path}")
    print(f"ğŸ“ edges.csv: {edges_path}")
    print(f"ğŸ“ graph.pt : {graph_path}")

    return nodes_path, edges_path, graph_path

def build_similarity_knn_graph(csv_path: str, save_dir: str, num_edges: int = 10):
    """
    åŸºäºæ ·æœ¬é—´ä½™å¼¦ç›¸ä¼¼åº¦ + KNN å»ºå›¾ã€‚
    å¿½ç•¥é¦–åˆ—(åºå·)ä¸æœ«åˆ—(æ ‡ç­¾)ï¼Œè¾“å‡ºç»“æ„ä¸ build_local_temporal_graph ä¸€è‡´ã€‚

    å‚æ•°:
        csv_path (str): è¾“å…¥CSVæ–‡ä»¶è·¯å¾„ã€‚
        save_dir (str): å›¾ç»“æ„æ–‡ä»¶çš„ä¿å­˜æ–‡ä»¶å¤¹ã€‚
        num_edges (int): æ¯ä¸ªèŠ‚ç‚¹è¿æ¥çš„é‚»ç‚¹æ•°(KNNæ•°é‡)ã€‚
    è¿”å›:
        (nodes_csv, edges_csv, graph_pt): ä¿å­˜çš„æ–‡ä»¶è·¯å¾„å…ƒç»„ã€‚
    """

    # ===================== 1ï¸âƒ£ è¯»å–æ•°æ® =====================
    if not os.path.exists(csv_path):
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶: {csv_path}")

    df = pd.read_csv(csv_path)
    print(f"ğŸ“Š å·²è¯»å–æ•°æ®: {df.shape}")

    # ğŸš« å¿½ç•¥é¦–åˆ—å’Œæœ«åˆ—
    if df.shape[1] <= 2:
        raise ValueError("âŒ æ•°æ®åˆ—æ•°è¿‡å°‘ï¼Œæ— æ³•åŒæ—¶å¿½ç•¥é¦–åˆ—å’Œæœ«åˆ—ã€‚")
    df = df.iloc[:, 1:-1]

    # ä»…ä¿ç•™æ•°å€¼åˆ—
    df = df.select_dtypes(include=["float", "int"])
    features = df.values.astype(np.float32)
    num_nodes = features.shape[0]
    print(f"ğŸ§© ä½¿ç”¨ç‰¹å¾åˆ—æ•°: {features.shape[1]} | å¿½ç•¥é¦–å°¾åˆ—å: {list(df.columns)[:5]} ...")

    # ===================== 2ï¸âƒ£ è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦çŸ©é˜µ =====================
    print("âš™ï¸ æ­£åœ¨è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦çŸ©é˜µ...")
    sim_matrix = cosine_similarity(features)
    np.fill_diagonal(sim_matrix, -np.inf)  # æ’é™¤è‡ªèº«

    # ===================== 3ï¸âƒ£ æ„å»º KNN è¾¹ =====================
    print(f"ğŸ” æ­£åœ¨ä¸ºæ¯ä¸ªèŠ‚ç‚¹é€‰å– {num_edges} ä¸ªæœ€ç›¸ä¼¼é‚»å±…...")
    edges = []
    for i in range(num_nodes):
        topk_idx = np.argpartition(sim_matrix[i], -num_edges)[-num_edges:]
        for j in topk_idx:
            edges.append([i, j])
            edges.append([j, i])  # æ— å‘è¾¹

    edges = np.array(edges)
    edge_index = torch.tensor(edges.T, dtype=torch.long)
    x = torch.tensor(features, dtype=torch.float)

    # ===================== 4ï¸âƒ£ æ„å»º PyG Data å¯¹è±¡ =====================
    data = Data(x=x, edge_index=edge_index)

    # ===================== 5ï¸âƒ£ ä¿å­˜æ–‡ä»¶ =====================
    os.makedirs(save_dir, exist_ok=True)
    base_name = os.path.splitext(os.path.basename(csv_path))[0]
    nodes_csv = os.path.join(save_dir, f"{base_name}_nodes.csv")
    edges_csv = os.path.join(save_dir, f"{base_name}_edges.csv")
    graph_pt = os.path.join(save_dir, f"{base_name}_graph.pt")

    # ä¿å­˜èŠ‚ç‚¹ä¸è¾¹æ–‡ä»¶
    pd.DataFrame(features).to_csv(nodes_csv, index=False)
    pd.DataFrame(edges, columns=["source", "target"]).to_csv(edges_csv, index=False)
    torch.save(data, graph_pt)

    print(f"âœ… å›¾æ„å»ºå®Œæˆï¼Œå…± {num_nodes} ä¸ªèŠ‚ç‚¹ï¼Œ{len(edges)//2} æ¡æ— å‘è¾¹ã€‚")
    print(f"ğŸ“ èŠ‚ç‚¹æ–‡ä»¶: {nodes_csv}")
    print(f"ğŸ“ è¾¹æ–‡ä»¶:   {edges_csv}")
    print(f"ğŸ“ å›¾æ–‡ä»¶:   {graph_pt}")

    return nodes_csv, edges_csv, graph_pt

def add_random_masks_to_pyg(
    graph_path: str,
    save_path: str = None,
    ratios: dict = {"train": 0.6, "val": 0.2, "test": 0.2},
    seed: int = 42
):
    """
    å‘ PyG æ ¼å¼çš„å›¾æ–‡ä»¶ä¸­æ·»åŠ éšæœºçš„ train/val/test æ©ç æ•°ç»„ã€‚
    
    å‚æ•°:
        graph_path (str): åŸå§‹å›¾æ–‡ä»¶è·¯å¾„ (.pt)ã€‚
        save_path (str): æ–°æ–‡ä»¶ä¿å­˜è·¯å¾„ï¼›è‹¥ä¸º Noneï¼Œåˆ™è¦†ç›–åŸæ–‡ä»¶ã€‚
        ratios (dict): å„æ©ç å æ¯”ï¼Œå¦‚ {"train":0.6, "val":0.2, "test":0.2}ã€‚
        seed (int): éšæœºç§å­ï¼Œä¿è¯å¯å¤ç°ã€‚
    
    è¿”å›:
        save_path (str): ä¿å­˜çš„æ–°å›¾æ–‡ä»¶è·¯å¾„ã€‚
    """

    # ===================== 1ï¸âƒ£ è¯»å–å›¾æ–‡ä»¶ =====================
    if not os.path.exists(graph_path):
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°å›¾æ–‡ä»¶: {graph_path}")
    
    data = torch.load(graph_path)
    num_nodes = data.num_nodes if hasattr(data, "num_nodes") else data.x.shape[0]
    print(f"ğŸ“¦ å·²åŠ è½½å›¾ï¼Œå…± {num_nodes} ä¸ªèŠ‚ç‚¹ã€‚")

    # ===================== 2ï¸âƒ£ æ£€æŸ¥å·²æœ‰æ©ç  =====================
    masks_exist = all(hasattr(data, k + "_mask") for k in ["train", "val", "test"])
    if masks_exist:
        print("âš ï¸ æ©ç å·²å­˜åœ¨ï¼Œæœªåšä¿®æ”¹ã€‚")
        return graph_path

    # ===================== 3ï¸âƒ£ ç”Ÿæˆéšæœºæ©ç  =====================
    np.random.seed(seed)
    indices = np.arange(num_nodes)
    np.random.shuffle(indices)

    n_train = int(num_nodes * ratios.get("train", 0.6))
    n_val   = int(num_nodes * ratios.get("val", 0.2))
    n_test  = num_nodes - n_train - n_val

    train_idx = indices[:n_train]
    val_idx   = indices[n_train:n_train + n_val]
    test_idx  = indices[n_train + n_val:]

    train_mask = torch.zeros(num_nodes, dtype=torch.bool)
    val_mask   = torch.zeros(num_nodes, dtype=torch.bool)
    test_mask  = torch.zeros(num_nodes, dtype=torch.bool)

    train_mask[train_idx] = True
    val_mask[val_idx]     = True
    test_mask[test_idx]   = True

    data.train_mask = train_mask
    data.val_mask = val_mask
    data.test_mask = test_mask

    print(f"âœ… æ©ç ç”Ÿæˆå®Œæˆï¼štrain={n_train}, val={n_val}, test={n_test}")

    # ===================== 4ï¸âƒ£ ä¿å­˜æ–‡ä»¶ =====================
    if save_path is None:
        save_path = graph_path  # è¦†ç›–åŸæ–‡ä»¶
    else:
        os.makedirs(os.path.dirname(save_path), exist_ok=True)

    torch.save(data, save_path)
    print(f"ğŸ’¾ æ–°å›¾æ–‡ä»¶å·²ä¿å­˜ï¼š{save_path}")

    return save_path

def add_random_masks_with_label_split(
    graph_path: str,
    save_path: str = None,
    ratios: dict = {"train": 0.6, "val": 0.2, "test": 0.2},
    train_label_ratio: float = 0.5,
    seed: int = 42
):
    """
    å‘ PyG å›¾æ–‡ä»¶ä¸­æ·»åŠ  train/val/test æ©ç ï¼Œ
    å¹¶åœ¨ train å†…éƒ¨åˆ’åˆ† train_withlabel_mask / train_nolabel_maskã€‚
    è‹¥æœªæŒ‡å®š save_pathï¼Œåˆ™è¦†ç›–åŸæ–‡ä»¶ã€‚

    å‚æ•°:
        graph_path (str): è¾“å…¥å›¾æ–‡ä»¶è·¯å¾„ (.pt)
        save_path (str): ä¿å­˜è·¯å¾„ï¼›è‹¥ä¸º Noneï¼Œåˆ™è¦†ç›–åŸæ–‡ä»¶
        ratios (dict): æ©ç å æ¯”ï¼Œå¦‚ {"train":0.6, "val":0.2, "test":0.2}
        train_label_ratio (float): åœ¨ train æ ·æœ¬ä¸­æœ‰æ ‡ç­¾æ¯”ä¾‹
        seed (int): éšæœºç§å­
    è¿”å›:
        save_path (str): ä¿å­˜çš„æ–°å›¾æ–‡ä»¶è·¯å¾„
    """

    # ===================== 1ï¸âƒ£ åŠ è½½ PyG å›¾ =====================
    if not os.path.exists(graph_path):
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°å›¾æ–‡ä»¶: {graph_path}")

    data = torch.load(graph_path)
    num_nodes = data.num_nodes if hasattr(data, "num_nodes") else data.x.shape[0]
    print(f"ğŸ“¦ å·²åŠ è½½å›¾æ–‡ä»¶ï¼Œå…± {num_nodes} ä¸ªèŠ‚ç‚¹ã€‚")

    # ===================== 2ï¸âƒ£ æ£€æŸ¥æ˜¯å¦å·²æœ‰æ©ç  =====================
    masks_exist = any(hasattr(data, m) for m in ["train_mask", "val_mask", "test_mask"])
    if masks_exist:
        print("âš ï¸ å·²æ£€æµ‹åˆ°å›¾ä¸­å­˜åœ¨éƒ¨åˆ†æ©ç ï¼Œå°†ä¸ä¼šè¦†ç›–å·²æœ‰æ©ç ã€‚")

    # ===================== 3ï¸âƒ£ éšæœºåˆ’åˆ†ç´¢å¼• =====================
    np.random.seed(seed)
    indices = np.random.permutation(num_nodes)

    n_train = int(num_nodes * ratios.get("train", 0.6))
    n_val   = int(num_nodes * ratios.get("val", 0.2))
    n_test  = num_nodes - n_train - n_val

    train_idx = indices[:n_train]
    val_idx   = indices[n_train:n_train + n_val]
    test_idx  = indices[n_train + n_val:]

    # ===================== 4ï¸âƒ£ ç”Ÿæˆä¸»æ©ç  =====================
    if not hasattr(data, "train_mask"):
        data.train_mask = torch.zeros(num_nodes, dtype=torch.bool)
        data.train_mask[train_idx] = True
    if not hasattr(data, "val_mask"):
        data.val_mask = torch.zeros(num_nodes, dtype=torch.bool)
        data.val_mask[val_idx] = True
    if not hasattr(data, "test_mask"):
        data.test_mask = torch.zeros(num_nodes, dtype=torch.bool)
        data.test_mask[test_idx] = True

    print(f"âœ… å·²ç”Ÿæˆä¸»æ©ç ï¼štrain={n_train}, val={n_val}, test={n_test}")

    # ===================== 5ï¸âƒ£ ç”Ÿæˆè®­ç»ƒå­æ©ç  =====================
    np.random.seed(seed + 1)
    n_withlabel = int(n_train * train_label_ratio)
    shuffled_train = np.random.permutation(train_idx)

    withlabel_idx = shuffled_train[:n_withlabel]
    nolabel_idx   = shuffled_train[n_withlabel:]

    data.train_withlabel_mask = torch.zeros(num_nodes, dtype=torch.bool)
    data.train_nolabel_mask   = torch.zeros(num_nodes, dtype=torch.bool)
    data.train_withlabel_mask[withlabel_idx] = True
    data.train_nolabel_mask[nolabel_idx] = True

    print(f"ğŸ¯ è®­ç»ƒé›†å†…éƒ¨åˆ’åˆ†ï¼šwith_label={n_withlabel}, no_label={len(nolabel_idx)}")

    # ===================== 6ï¸âƒ£ ä¿å­˜é€»è¾‘ =====================
    if save_path and save_path.strip():
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        torch.save(data, save_path)
        print(f"ğŸ’¾ å·²å°†å«æ©ç çš„æ–°å›¾æ–‡ä»¶ä¿å­˜è‡³ï¼š{save_path}")
    else:
        torch.save(data, graph_path)
        save_path = graph_path
        print(f"ğŸ’¾ æœªæŒ‡å®šä¿å­˜è·¯å¾„ï¼Œå·²è¦†ç›–åŸæ–‡ä»¶ï¼š{graph_path}")

    return save_path