import os
import scipy.io as sio
import pandas as pd
import numpy as np
import torch
from torch_geometric.data import Data
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.neighbors import NearestNeighbors

def build_local_temporal_graph(
    csv_path: str,
    save_dir: str,
    num_edges: int = 10,
    label_col: int = None
):
    """
    åŸºäºæ—¶é—´é¡ºåºæ„å»ºå±€éƒ¨æ—¶åºå›¾ã€‚
    æ¯ä¸€è¡Œæ˜¯ä¸€ä¸ªèŠ‚ç‚¹ï¼Œä¸Šä¸‹ç›¸é‚»æ ·æœ¬æ„æˆè¾¹ã€‚
    æ ‡ç­¾åˆ—å¯æŒ‡å®šç´¢å¼•ï¼Œè‹¥ä¸æŒ‡å®šåˆ™é»˜è®¤æœ€åä¸€åˆ—ã€‚
    ğŸš« è‡ªåŠ¨å¿½ç•¥é¦–åˆ—ï¼ˆå¸¸ç”¨äºåºå·/IDï¼‰ï¼Œé¿å…è¯¯å…¥ç‰¹å¾è®¡ç®—ã€‚

    å‚æ•°:
        csv_path (str): è¾“å…¥ CSV æ–‡ä»¶è·¯å¾„ã€‚
        save_dir (str): å›¾ç»“æ„æ–‡ä»¶çš„ä¿å­˜æ–‡ä»¶å¤¹ã€‚
        num_edges (int): æ¯ä¸ªèŠ‚ç‚¹çš„è¾¹æ•°ï¼ˆä¸Šä¸‹å¹³å‡åˆ†é…ï¼‰ã€‚
        label_col (int): æ ‡ç­¾åˆ—ç´¢å¼•ï¼ˆé»˜è®¤ None â†’ æœ€åä¸€åˆ—ï¼‰ã€‚
    è¿”å›:
        (nodes_csv, edges_csv, graph_pt): ä¿å­˜çš„æ–‡ä»¶è·¯å¾„å…ƒç»„ã€‚
    """
    os.makedirs(save_dir, exist_ok=True)

    # === è¯»å–æ•°æ® ===
    df = pd.read_csv(csv_path)
    num_nodes = len(df)
    if num_nodes == 0:
        raise ValueError("âŒ è¾“å…¥ CSV æ–‡ä»¶ä¸ºç©ºã€‚")

    # === æ ‡ç­¾åˆ—åˆ¤æ–­ ===
    if label_col is None:
        label_col = df.shape[1] - 1

    # === æå–æ ‡ç­¾åˆ— ===
    y = torch.tensor(df.iloc[:, label_col].values, dtype=torch.long)

    # === æ„é€ ç‰¹å¾åˆ—ï¼ˆå»æ‰é¦–åˆ— + æ ‡ç­¾åˆ—ï¼‰===
    drop_cols = [df.columns[0], df.columns[label_col]] if label_col != 0 else [df.columns[0]]
    df_features = df.drop(columns=drop_cols, errors="ignore")

    # ä¿ç•™æ•°å€¼åˆ—
    df_features = df_features.select_dtypes(include=["float", "int"])
    if df_features.shape[1] == 0:
        raise ValueError("âŒ ç‰¹å¾åˆ—ä¸ºç©ºï¼Œè¯·æ£€æŸ¥è¾“å…¥ CSVã€‚")

    # === æ„å»ºè¾¹ ===
    half = num_edges // 2
    edges = []
    for i in range(num_nodes):
        start_up = max(0, i - half)
        end_down = min(num_nodes, i + half + 1)
        up_neighbors = list(range(start_up, i))
        down_neighbors = list(range(i + 1, end_down))

        total_needed = num_edges
        current = len(up_neighbors) + len(down_neighbors)
        if current < total_needed:
            remaining = total_needed - current
            if i + half + 1 >= num_nodes:  # ä¸‹æ–¹ä¸å¤Ÿ
                extra_up = list(range(max(0, start_up - remaining), start_up))
                up_neighbors = extra_up + up_neighbors
            elif i - half < 0:  # ä¸Šæ–¹ä¸å¤Ÿ
                extra_down = list(range(end_down, min(num_nodes, end_down + remaining)))
                down_neighbors += extra_down

        for j in up_neighbors + down_neighbors:
            edges.append((i, j))
            edges.append((j, i))

    # === ä¿å­˜èŠ‚ç‚¹ä¸è¾¹ ===
    nodes_path = os.path.join(save_dir, "nodes.csv")
    edges_path = os.path.join(save_dir, "edges.csv")
    graph_path = os.path.join(save_dir, "graph.pt")

    df_features.to_csv(nodes_path, index=False)
    pd.DataFrame(edges, columns=["source", "target"]).to_csv(edges_path, index=False)

    # === æ„å»º PyG å›¾ç»“æ„ ===
    edge_index = torch.tensor(edges, dtype=torch.long).T
    x = torch.tensor(df_features.values, dtype=torch.float)
    data = Data(x=x, edge_index=edge_index, y=y)

    torch.save(data, graph_path)

    print(f"âœ… å›¾ç»“æ„æ„å»ºå®Œæˆï¼Œå…± {num_nodes} ä¸ªèŠ‚ç‚¹ï¼Œ{len(edges)//2} æ¡æ— å‘è¾¹")
    print(f"ğŸ“ nodes.csv: {nodes_path}")
    print(f"ğŸ“ edges.csv: {edges_path}")
    print(f"ğŸ“ graph.pt : {graph_path}")
    print(f"ğŸ§© ç‰¹å¾ç»´åº¦: {x.shape[1]} (å·²è‡ªåŠ¨å¿½ç•¥é¦–åˆ—ä¸æ ‡ç­¾åˆ—)")

    return nodes_path, edges_path, graph_path


def build_similarity_knn_graph(
    csv_path: str,
    save_dir: str,
    num_edges: int = 10,
    label_col: int = None,
    block_size: int = 5000
):
    """
    åŸºäºä½™å¼¦ç›¸ä¼¼åº¦ + KNN å»ºå›¾ï¼ˆåˆ†å—è®¡ç®—ç‰ˆï¼Œä½å†…å­˜ï¼‰ã€‚
    ğŸš« è‡ªåŠ¨å¿½ç•¥é¦–åˆ—ï¼ˆåºå·ï¼‰ä¸æ ‡ç­¾åˆ—ã€‚
    âœ… æ”¯æŒ data.yã€‚
    âœ… è¾“å‡º nodes.csv / edges.csv / graph.ptã€‚

    å‚æ•°:
        csv_path (str): è¾“å…¥ CSV æ–‡ä»¶è·¯å¾„ã€‚
        save_dir (str): å›¾æ–‡ä»¶è¾“å‡ºæ–‡ä»¶å¤¹ã€‚
        num_edges (int): æ¯ä¸ªèŠ‚ç‚¹è¿æ¥çš„é‚»ç‚¹æ•° (KNNæ•°é‡)ã€‚
        label_col (int): æ ‡ç­¾åˆ—ç´¢å¼•ï¼ˆé»˜è®¤ None â†’ æœ€åä¸€åˆ—ï¼‰ã€‚
        block_size (int): åˆ†å—è®¡ç®—å¤§å°ï¼ˆè¶Šå°è¶Šçœå†…å­˜ï¼‰ã€‚
    è¿”å›:
        (nodes_csv, edges_csv, graph_pt)
    """

    # ===================== 1ï¸âƒ£ è¯»å–æ•°æ® =====================
    if not os.path.exists(csv_path):
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶: {csv_path}")

    df = pd.read_csv(csv_path)
    print(f"ğŸ“Š å·²è¯»å–æ•°æ®: {df.shape}")

    # === æå–æ ‡ç­¾åˆ— ===
    if label_col is None:
        label_col = df.shape[1] - 1
    y = torch.tensor(df.iloc[:, label_col].values, dtype=torch.long)

    # === å¿½ç•¥é¦–åˆ—ä¸æ ‡ç­¾åˆ— ===
    drop_cols = [df.columns[0], df.columns[label_col]] if label_col != 0 else [df.columns[0]]
    df_features = df.drop(columns=drop_cols, errors="ignore")
    df_features = df_features.select_dtypes(include=["float", "int"])
    features = df_features.values.astype(np.float32)
    num_nodes = features.shape[0]
    print(f"ğŸ§© ä½¿ç”¨ç‰¹å¾åˆ—æ•°: {features.shape[1]} | èŠ‚ç‚¹æ•°: {num_nodes}")

    # ===================== 2ï¸âƒ£ åˆ†å—è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ =====================
    edges = []
    print(f"âš™ï¸ åˆ†å—è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œæ¯å— {block_size} èŠ‚ç‚¹ï¼Œç›®æ ‡é‚»ç‚¹æ•°={num_edges}")

    for start in range(0, num_nodes, block_size):
        end = min(num_nodes, start + block_size)
        block = features[start:end]

        # è®¡ç®— block ä¸å…¨ä½“æ ·æœ¬çš„ç›¸ä¼¼åº¦
        sim_part = cosine_similarity(block, features)
        np.fill_diagonal(sim_part[:, start:end], -np.inf)

        # å–å‰ num_edges ä¸ªæœ€ç›¸ä¼¼èŠ‚ç‚¹
        for bi in range(sim_part.shape[0]):
            global_i = start + bi
            topk_idx = np.argpartition(sim_part[bi], -num_edges)[-num_edges:]
            for j in topk_idx:
                edges.append((global_i, j))
                edges.append((j, global_i))

        print(f"  âœ… å·²å¤„ç† {end}/{num_nodes} èŠ‚ç‚¹å—")

    edges = np.array(edges, dtype=np.int64)
    edge_index = torch.tensor(edges.T, dtype=torch.long)
    x = torch.tensor(features, dtype=torch.float)

    # ===================== 3ï¸âƒ£ æ„é€  PyG Data =====================
    data = Data(x=x, edge_index=edge_index, y=y)

    # ===================== 4ï¸âƒ£ ä¿å­˜æ–‡ä»¶ =====================
    os.makedirs(save_dir, exist_ok=True)
    base_name = os.path.splitext(os.path.basename(csv_path))[0]
    nodes_csv = os.path.join(save_dir, f"{base_name}_nodes.csv")
    edges_csv = os.path.join(save_dir, f"{base_name}_edges.csv")
    graph_pt = os.path.join(save_dir, f"{base_name}_graph.pt")

    pd.DataFrame(features).to_csv(nodes_csv, index=False)
    pd.DataFrame(edges, columns=["source", "target"]).to_csv(edges_csv, index=False)
    torch.save(data, graph_pt)

    print(f"\nâœ… å›¾æ„å»ºå®Œæˆï¼Œå…± {num_nodes} ä¸ªèŠ‚ç‚¹ï¼Œ{len(edges)//2} æ¡æ— å‘è¾¹ã€‚")
    print(f"ğŸ“ èŠ‚ç‚¹æ–‡ä»¶: {nodes_csv}")
    print(f"ğŸ“ è¾¹æ–‡ä»¶:   {edges_csv}")
    print(f"ğŸ“ å›¾æ–‡ä»¶:   {graph_pt}")

    return nodes_csv, edges_csv, graph_pt

def add_random_masks_to_pyg(
    graph_path: str,
    save_path: str = None,
    ratios: dict = {"train": 0.6, "val": 0.2, "test": 0.2},
    seed: int = 42
):
    """
    å‘ PyG æ ¼å¼çš„å›¾æ–‡ä»¶ä¸­æ·»åŠ éšæœºçš„ train/val/test æ©ç æ•°ç»„ã€‚
    
    å‚æ•°:
        graph_path (str): åŸå§‹å›¾æ–‡ä»¶è·¯å¾„ (.pt)ã€‚
        save_path (str): æ–°æ–‡ä»¶ä¿å­˜è·¯å¾„ï¼›è‹¥ä¸º Noneï¼Œåˆ™è¦†ç›–åŸæ–‡ä»¶ã€‚
        ratios (dict): å„æ©ç å æ¯”ï¼Œå¦‚ {"train":0.6, "val":0.2, "test":0.2}ã€‚
        seed (int): éšæœºç§å­ï¼Œä¿è¯å¯å¤ç°ã€‚
    
    è¿”å›:
        save_path (str): ä¿å­˜çš„æ–°å›¾æ–‡ä»¶è·¯å¾„ã€‚
    """

    # ===================== 1ï¸âƒ£ è¯»å–å›¾æ–‡ä»¶ =====================
    if not os.path.exists(graph_path):
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°å›¾æ–‡ä»¶: {graph_path}")
    
    data = torch.load(graph_path)
    num_nodes = data.num_nodes if hasattr(data, "num_nodes") else data.x.shape[0]
    print(f"ğŸ“¦ å·²åŠ è½½å›¾ï¼Œå…± {num_nodes} ä¸ªèŠ‚ç‚¹ã€‚")

    # ===================== 2ï¸âƒ£ æ£€æŸ¥å·²æœ‰æ©ç  =====================
    masks_exist = all(hasattr(data, k + "_mask") for k in ["train", "val", "test"])
    if masks_exist:
        print("âš ï¸ æ©ç å·²å­˜åœ¨ï¼Œæœªåšä¿®æ”¹ã€‚")
        return graph_path

    # ===================== 3ï¸âƒ£ ç”Ÿæˆéšæœºæ©ç  =====================
    np.random.seed(seed)
    indices = np.arange(num_nodes)
    np.random.shuffle(indices)

    n_train = int(num_nodes * ratios.get("train", 0.6))
    n_val   = int(num_nodes * ratios.get("val", 0.2))
    n_test  = num_nodes - n_train - n_val

    train_idx = indices[:n_train]
    val_idx   = indices[n_train:n_train + n_val]
    test_idx  = indices[n_train + n_val:]

    train_mask = torch.zeros(num_nodes, dtype=torch.bool)
    val_mask   = torch.zeros(num_nodes, dtype=torch.bool)
    test_mask  = torch.zeros(num_nodes, dtype=torch.bool)

    train_mask[train_idx] = True
    val_mask[val_idx]     = True
    test_mask[test_idx]   = True

    data.train_mask = train_mask
    data.val_mask = val_mask
    data.test_mask = test_mask

    print(f"âœ… æ©ç ç”Ÿæˆå®Œæˆï¼štrain={n_train}, val={n_val}, test={n_test}")

    # ===================== 4ï¸âƒ£ ä¿å­˜æ–‡ä»¶ =====================
    if save_path is None:
        save_path = graph_path  # è¦†ç›–åŸæ–‡ä»¶
    else:
        os.makedirs(os.path.dirname(save_path), exist_ok=True)

    torch.save(data, save_path)
    print(f"ğŸ’¾ æ–°å›¾æ–‡ä»¶å·²ä¿å­˜ï¼š{save_path}")

    return save_path

def add_random_masks_with_label_split(
    graph_path: str,
    save_path: str = None,
    ratios: dict = {"train": 0.6, "val": 0.2, "test": 0.2},
    train_label_ratio: float = 0.5,
    seed: int = 42
):
    """
    å‘ PyG å›¾æ–‡ä»¶ä¸­æ·»åŠ  train/val/test æ©ç ï¼Œ
    å¹¶åœ¨ train å†…éƒ¨åˆ’åˆ† train_withlabel_mask / train_nolabel_maskã€‚
    è‹¥æœªæŒ‡å®š save_pathï¼Œåˆ™è¦†ç›–åŸæ–‡ä»¶ã€‚

    å‚æ•°:
        graph_path (str): è¾“å…¥å›¾æ–‡ä»¶è·¯å¾„ (.pt)
        save_path (str): ä¿å­˜è·¯å¾„ï¼›è‹¥ä¸º Noneï¼Œåˆ™è¦†ç›–åŸæ–‡ä»¶
        ratios (dict): æ©ç å æ¯”ï¼Œå¦‚ {"train":0.6, "val":0.2, "test":0.2}
        train_label_ratio (float): åœ¨ train æ ·æœ¬ä¸­æœ‰æ ‡ç­¾æ¯”ä¾‹
        seed (int): éšæœºç§å­
    è¿”å›:
        save_path (str): ä¿å­˜çš„æ–°å›¾æ–‡ä»¶è·¯å¾„
    """

    # ===================== 1ï¸âƒ£ åŠ è½½ PyG å›¾ =====================
    if not os.path.exists(graph_path):
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°å›¾æ–‡ä»¶: {graph_path}")

    data = torch.load(graph_path)
    num_nodes = data.num_nodes if hasattr(data, "num_nodes") else data.x.shape[0]
    print(f"ğŸ“¦ å·²åŠ è½½å›¾æ–‡ä»¶ï¼Œå…± {num_nodes} ä¸ªèŠ‚ç‚¹ã€‚")

    # ===================== 2ï¸âƒ£ æ£€æŸ¥æ˜¯å¦å·²æœ‰æ©ç  =====================
    masks_exist = any(hasattr(data, m) for m in ["train_mask", "val_mask", "test_mask"])
    if masks_exist:
        print("âš ï¸ å·²æ£€æµ‹åˆ°å›¾ä¸­å­˜åœ¨éƒ¨åˆ†æ©ç ï¼Œå°†ä¸ä¼šè¦†ç›–å·²æœ‰æ©ç ã€‚")

    # ===================== 3ï¸âƒ£ éšæœºåˆ’åˆ†ç´¢å¼• =====================
    np.random.seed(seed)
    indices = np.random.permutation(num_nodes)

    n_train = int(num_nodes * ratios.get("train", 0.6))
    n_val   = int(num_nodes * ratios.get("val", 0.2))
    n_test  = num_nodes - n_train - n_val

    train_idx = indices[:n_train]
    val_idx   = indices[n_train:n_train + n_val]
    test_idx  = indices[n_train + n_val:]

    # ===================== 4ï¸âƒ£ ç”Ÿæˆä¸»æ©ç  =====================
    if not hasattr(data, "train_mask"):
        data.train_mask = torch.zeros(num_nodes, dtype=torch.bool)
        data.train_mask[train_idx] = True
    if not hasattr(data, "val_mask"):
        data.val_mask = torch.zeros(num_nodes, dtype=torch.bool)
        data.val_mask[val_idx] = True
    if not hasattr(data, "test_mask"):
        data.test_mask = torch.zeros(num_nodes, dtype=torch.bool)
        data.test_mask[test_idx] = True

    print(f"âœ… å·²ç”Ÿæˆä¸»æ©ç ï¼štrain={n_train}, val={n_val}, test={n_test}")

    # ===================== 5ï¸âƒ£ ç”Ÿæˆè®­ç»ƒå­æ©ç  =====================
    np.random.seed(seed + 1)
    n_withlabel = int(n_train * train_label_ratio)
    shuffled_train = np.random.permutation(train_idx)

    withlabel_idx = shuffled_train[:n_withlabel]
    nolabel_idx   = shuffled_train[n_withlabel:]

    data.train_withlabel_mask = torch.zeros(num_nodes, dtype=torch.bool)
    data.train_nolabel_mask   = torch.zeros(num_nodes, dtype=torch.bool)
    data.train_withlabel_mask[withlabel_idx] = True
    data.train_nolabel_mask[nolabel_idx] = True

    print(f"ğŸ¯ è®­ç»ƒé›†å†…éƒ¨åˆ’åˆ†ï¼šwith_label={n_withlabel}, no_label={len(nolabel_idx)}")

    # ===================== 6ï¸âƒ£ ä¿å­˜é€»è¾‘ =====================
    if save_path and save_path.strip():
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        torch.save(data, save_path)
        print(f"ğŸ’¾ å·²å°†å«æ©ç çš„æ–°å›¾æ–‡ä»¶ä¿å­˜è‡³ï¼š{save_path}")
    else:
        torch.save(data, graph_path)
        save_path = graph_path
        print(f"ğŸ’¾ æœªæŒ‡å®šä¿å­˜è·¯å¾„ï¼Œå·²è¦†ç›–åŸæ–‡ä»¶ï¼š{graph_path}")

    return save_path